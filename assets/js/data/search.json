[ { "title": "6.s081 lab7 Multhreading", "url": "/posts/6.s081-lab7-Multhreading/", "categories": "计算机", "tags": "操作系统/6S081", "date": "2024-02-10 02:34:00 +0000", "snippet": "#操作系统/6S081Uthread: switching between threads题目一开始就提供的 uthread.c实验目的补充一个三线程一次从0增加到100，在题目给出的代码中，缺少的是： 线程间寄存器的切换 汇编代码 线程的上下文定义 线程上下文的初始化 要着重注意 返回地址 和 栈指针指向 - user/uthread.c cod...", "content": "#操作系统/6S081Uthread: switching between threads题目一开始就提供的 uthread.c实验目的补充一个三线程一次从0增加到100，在题目给出的代码中，缺少的是： 线程间寄存器的切换 汇编代码 线程的上下文定义 线程上下文的初始化 要着重注意 返回地址 和 栈指针指向 - user/uthread.c code #include \"kernel/types.h\"#include \"kernel/stat.h\"#include \"user/user.h\"/* Possible states of a thread: */#define FREE 0x0#define RUNNING 0x1#define RUNNABLE 0x2// 8192 就是每个栈的大小#define STACK_SIZE 8192#define MAX_THREAD 4===-struct context { uint64 ra; uint64 sp; // callee-saved uint64 s0; uint64 s1; uint64 s2; uint64 s3; uint64 s4; uint64 s5; uint64 s6; uint64 s7; uint64 s8; uint64 s9; uint64 s10; uint64 s11;}; -===struct thread { char stack[STACK_SIZE]; /* the thread's stack */ int state; /* FREE, RUNNING, RUNNABLE */ ===- struct context context; -===};struct thread all_thread[MAX_THREAD];struct thread *current_thread;===-extern void thread_switch(struct context*, struct context*);-=== void thread_init(void){ // main() is thread 0, which will make the first invocation to // thread_schedule(). it needs a stack so that the first thread_switch() can // save thread 0's state. thread_schedule() won't run the main thread ever // again, because its state is set to RUNNING, and thread_schedule() selects // a RUNNABLE thread. current_thread = &amp;all_thread[0]; current_thread-&gt;state = RUNNING;}void thread_schedule(void){ struct thread *t, *next_thread; /* Find another runnable thread. */ next_thread = 0; t = current_thread + 1; for(int i = 0; i &lt; MAX_THREAD; i++){ if(t &gt;= all_thread + MAX_THREAD) t = all_thread; if(t-&gt;state == RUNNABLE) { next_thread = t; break; } t = t + 1; } if (next_thread == 0) { printf(\"thread_schedule: no runnable threads\\n\"); exit(-1); } if (current_thread != next_thread) { /* switch threads? */ next_thread-&gt;state = RUNNING; t = current_thread; current_thread = next_thread; /* YOUR CODE HERE * Invoke thread_switch to switch from t to next_thread: * thread_switch(??, ??); */===- thread_switch(&amp;t-&gt;context, &amp;current_thread-&gt;context);-=== } else next_thread = 0;}void thread_create(void (*func)()){ struct thread *t; for (t = all_thread; t &lt; all_thread + MAX_THREAD; t++) { if (t-&gt;state == FREE) break; } t-&gt;state = RUNNABLE; // YOUR CODE HERE ===- memset(&amp;t-&gt;context, 0, sizeof(t-&gt;context)); t-&gt;context.ra = (uint64)func; t-&gt;context.sp = (uint64)(t-&gt;stack + STACK_SIZE - 1); -===}void thread_yield(void){ current_thread-&gt;state = RUNNABLE; thread_schedule();}volatile int a_started, b_started, c_started;volatile int a_n, b_n, c_n;void thread_a(void){ int i; printf(\"thread_a started\\n\"); a_started = 1; while(b_started == 0 || c_started == 0) thread_yield(); for (i = 0; i &lt; 100; i++) { printf(\"thread_a %d\\n\", i); a_n += 1; thread_yield(); } printf(\"thread_a: exit after %d\\n\", a_n); current_thread-&gt;state = FREE; thread_schedule();}void thread_b(void){ int i; printf(\"thread_b started\\n\"); b_started = 1; while(a_started == 0 || c_started == 0) thread_yield(); for (i = 0; i &lt; 100; i++) { printf(\"thread_b %d\\n\", i); b_n += 1; thread_yield(); } printf(\"thread_b: exit after %d\\n\", b_n); current_thread-&gt;state = FREE; thread_schedule();}void thread_c(void){ int i; printf(\"thread_c started\\n\"); c_started = 1; while(a_started == 0 || b_started == 0) thread_yield(); for (i = 0; i &lt; 100; i++) { printf(\"thread_c %d\\n\", i); c_n += 1; thread_yield(); } printf(\"thread_c: exit after %d\\n\", c_n); current_thread-&gt;state = FREE; thread_schedule();}int main(int argc, char *argv[]) { a_started = b_started = c_started = 0; a_n = b_n = c_n = 0; thread_init(); thread_create(thread_a); thread_create(thread_b); thread_create(thread_c); thread_schedule(); exit(0);}Using threads解决哈希表操作中，由于静态竞争所导致的数据丢失基础方案那么要解决锁竞争的问题，就需要保证对更改数据时的操作进行保护，最基本的操作就是// ph.cpthread_mutex_t lock;intmain(int argc, char *argv[]){ pthread_t *tha; void *value; double t1, t0; pthread_mutex_init(&amp;lock, NULL); // ......}static void put(int key, int value){ NBUCKET; pthread_mutex_lock(&amp;lock); // ...... pthread_mutex_unlock(&amp;lock);}static struct entry*get(int key){ $ NBUCKET; pthread_mutex_lock(&amp;lock); // ...... pthread_mutex_unlock(&amp;lock); return e;}对 put 和 get 进行加锁，这样就能够通过测试，但是多线程的效果跟单线程的效果是一样的，所以我们还要对锁进行优化 - 增加锁的精细度进阶优化因为哈希操作对于每个桶的影响是分开的，所以对每个桶（键）分别创建一个锁，然后再 put 和 get 函数时，加上对应的桶的锁// ph.cpthread_mutex_t locks;intmain(int argc, char *argv[]){ pthread_t *tha; void *value; double t1, t0; for(int i=0;i&lt;NBUCKET;i++) { pthread_mutex_init(&amp;locks[i], NULL); } // ......}static void put(int key, int value){ int i = key % NBUCKET; pthread_mutex_lock(&amp;locks[i]); // ...... pthread_mutex_unlock(&amp;locks[i]);}static struct entry*get(int key){ int i = key % NBUCKET; pthread_mutex_lock(&amp;locks[i]); // ...... pthread_mutex_unlock(&amp;locks[i]); return e;}Barrier (moderate)实现 Barrier 保证线程的 变量i 和 变量线程经过的轮数 的数值一致static void *thread(void *xa){ long n = (long) xa; long delay; int i; for (i = 0; i &lt; 20000; i++) { int t = bstate.round; assert (i == t); barrier(); usleep(random() % 100); } return 0;}所以我们要通过条件变量的方式来实现线程的同步， barrier() 能够将 nthread个的线程卡住，当经过的线程到达一定数值时，唤醒所有线程【注意：由于 bstate.nthread 的判断也不是原子性的，所以要对齐进行加锁】static void barrier(){ pthread_mutex_lock(&amp;bstate.barrier_mutex); if (++bstate.nthread &gt;= nthread) { pthread_cond_broadcast(&amp;bstate.barrier_cond); bstate.round += 1; bstate.nthread = 0; } else { pthread_cond_wait(&amp;bstate.barrier_cond, &amp;bstate.barrier_mutex); } pthread_mutex_unlock(&amp;bstate.barrier_mutex);}" }, { "title": "6.s081 lab6 - copy-on-write fork", "url": "/posts/6.s081-lab6-copy-on-write-fork/", "categories": "计算机", "tags": "操作系统/6S081", "date": "2024-02-10 02:34:00 +0000", "snippet": "#操作系统/6S081什么是 COW这是懒分配的一个方法，在fork的时候 让子进程一起使用父进程的内存，避免fork占有无意义的内存，在当占有的内存被使用时，才开始创建新的内存实现要点 要怎么实现fork分配后，子进程使用父进程内存； 系统怎么知道你是父进程跟子进程一起使用的 通过COW处理的内存； 在子进程分配后，父进程虚拟页表并没有被处理，如何防止父进程的内存被再次分配； 父子...", "content": "#操作系统/6S081什么是 COW这是懒分配的一个方法，在fork的时候 让子进程一起使用父进程的内存，避免fork占有无意义的内存，在当占有的内存被使用时，才开始创建新的内存实现要点 要怎么实现fork分配后，子进程使用父进程内存； 系统怎么知道你是父进程跟子进程一起使用的 通过COW处理的内存； 在子进程分配后，父进程虚拟页表并没有被处理，如何防止父进程的内存被再次分配； 父子进程指向同一个虚拟内存时，如何保证物理地址不被重复释放； 物理页表的引用计数，如何避免静态竞争导致所导致的错误； - 大概要点就这么多吧代码实现kernel/kalloc.h```c===-struct spinlock pgreflock;#define paNum(pa) ((pa - KERNBASE)/PGSIZE)#define PG_MAX_NUM paNum(PHYSTOP)int paref_ID[PG_MAX_NUM];#define PA_REF(pa) paref_ID[paNum((uint64)pa)]-===struct {struct spinlock lock;struct run *freelist;===-int cnt;-===} kmem;voidkinit(){initlock(&amp;kmem.lock, \"kmem\");===-initlock(&amp;pgreflock, \"pgref\");-===freerange(end, (void*)PHYSTOP);}voidkfree(void *pa){struct run *r;if(((uint64)pa % PGSIZE) != 0 || (char*)pa &lt; end || (uint64)pa &gt;= PHYSTOP) panic(\"kfree\");===-acquire(&amp;pgreflock);if (--PA_REF(pa) &lt;= 0) {-=== // Fill with junk to catch dangling refs. memset(pa, 1, PGSIZE); r = (struct run*)pa; acquire(&amp;kmem.lock); r-&gt;next = kmem.freelist; kmem.freelist = r; release(&amp;kmem.lock); ===-}release(&amp;pgreflock);-===}void *kalloc(void){struct run *r;acquire(&amp;kmem.lock);r = kmem.freelist;if(r) kmem.freelist = r-&gt;next;release(&amp;kmem.lock);if(r) { memset((char*)r, 5, PGSIZE); // fill with junk ===- PA_REF(r) = 1; -===}return (void*)r;}===-// 当遇到cow虚拟页时，看引用计数去对应分配内存void*cow_copy(void* pa){uint64 mem;acquire(&amp;pgreflock);if (PA_REF(pa) &lt;= 1) { release(&amp;pgreflock); return pa;}mem = (uint64)kalloc();if (mem == 0) { release(&amp;pgreflock); return 0;}memmove((void*)mem, pa, PGSIZE);PA_REF(pa) -= 1;release(&amp;pgreflock);return (void*)mem;acquire(&amp;pgreflock);}// 查看物理页的引用计数int inspectPaRef(uint64 pa) {return PA_REF(pa);}voidincreace_ref(void* pa) {acquire(&amp;pgreflock);PA_REF(pa)++;release(&amp;pgreflock);}-===```##### `kernel/risc.h````c#define PTE_RSW (1L &lt;&lt; 8)```##### `kernel/trap.c````cvoidusertrap(void){int which_dev = 0;if((r_sstatus() &amp; SSTATUS_SPP) != 0) panic(\"usertrap: not from user mode\");// send interrupts and exceptions to kerneltrap(),// since we're now in the kernel.w_stvec((uint64)kernelvec);struct proc *p = myproc();// save user program counter.p-&gt;trapframe-&gt;epc = r_sepc();if(r_scause() == 8){ // system call if(p-&gt;killed) exit(-1); // sepc points to the ecall instruction, // but we want to return to the next instruction. p-&gt;trapframe-&gt;epc += 4; // an interrupt will change sstatus &amp;c registers, // so don't enable until done with those registers. intr_on(); syscall();} else if((which_dev = devintr()) != 0){ // ok===-} else if ((r_scause() == 13 || r_scause() == 15) &amp;&amp; inspectpte(r_stval())) { if (uvmcowrealcopy(r_stval()) == -1) { p-&gt;killed = 1; }}-=== else { printf(\"usertrap(): unexpected scause %p pid=%d\\n\", r_scause(), p-&gt;pid); printf(\" sepc=%p stval=%p\\n\", r_sepc(), r_stval()); p-&gt;killed = 1;}if(p-&gt;killed) exit(-1);// give up the CPU if this is a timer interrupt.if(which_dev == 2) yield();usertrapret();} ```kernel/vm.c```c===-intuvmcowlazycopy(pagetable_t old, pagetable_t new, uint64 sz) {pte_t *pte;uint64 pa, i;uint flags;for (i = 0; i &lt; sz; i += PGSIZE) { if ((pte = walk(old, i, 0)) == 0) panic(\"uvmlazycopy: pte should exist\"); if ((*pte &amp; PTE_V) == 0) panic(\"uvmlazycopy: page not present\"); pa = PTE2PA(*pte); if (*pte &amp; PTE_W) { *pte = (*pte &amp; ~PTE_W) | PTE_RSW; } flags = PTE_FLAGS(*pte); if(mappages(new, i, PGSIZE, pa, flags) != 0){ goto err; } increace_ref((void*) pa);}return 0;err:uvmunmap(new, 0, i / PGSIZE, 1);return -1;}intuvmcowrealcopy(uint64 va) {pte_t *pte;uint64 pa;struct proc *p = myproc();uint64 mem;uint flag;if ((pte = walk(p-&gt;pagetable, va, 0)) == 0) { vmprint(p-&gt;pagetable, 0); panic(\"uvmcowrealcopy: pte should exist\");}pa = PTE2PA(*pte);// if (inspectPaRef(pa) == 1) {// mem = pa;// } else {mem = (uint64)cow_copy((void*) pa);// }if (mem == 0) return -1;flag = (PTE_FLAGS(*pte) | PTE_W) &amp; ~PTE_RSW;uvmunmap(p-&gt;pagetable, PGROUNDDOWN(va), 1, 0);if (mappages(p-&gt;pagetable, va, 1, mem, flag) == -1) panic(\"uvmcowrealcopy: mappages\");return 0;}intinspectpte(uint64 va) {pte_t *pte;struct proc *p = myproc();return va &lt; p-&gt;sz &amp;&amp;((pte = walk(p-&gt;pagetable, va, 0)) != 0) &amp;&amp;(*pte &amp; PTE_RSW) &amp;&amp; (*pte &amp; PTE_V);}-===intcopyout(pagetable_t pagetable, uint64 dstva, char *src, uint64 len){uint64 n, va0, pa0;while(len &gt; 0){===- if (inspectpte(dstva)) { uvmcowrealcopy(dstva); }-=== va0 = PGROUNDDOWN(dstva); pa0 = walkaddr(pagetable, va0); if(pa0 == 0) return -1; n = PGSIZE - (dstva - va0); if(n &gt; len) n = len; memmove((void *)(pa0 + (dstva - va0)), src, n); len -= n; src += n; dstva = va0 + PGSIZE;}return 0;}```" }, { "title": "xv6 console.c 文件代码解析", "url": "/posts/xv6-console.c-%E6%96%87%E4%BB%B6%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90/", "categories": "计算机", "tags": "操作系统/6S081/源码解析", "date": "2024-01-27 02:34:00 +0000", "snippet": "#操作系统/6S081/源码解析 源代码地址void consputc(int c)当遇到退格符时，执行 uartputc_sync('\\b'); uartputc_sync(' '); uartputc_sync('\\b'); 代码该代码的作用是 将光标往前移动一个，在输出空格覆盖，再将光标往前移动一格。如果不是退格符，则执行 uartputc_sync 将字符输出void uartput...", "content": "#操作系统/6S081/源码解析 源代码地址void consputc(int c)当遇到退格符时，执行 uartputc_sync('\\b'); uartputc_sync(' '); uartputc_sync('\\b'); 代码该代码的作用是 将光标往前移动一个，在输出空格覆盖，再将光标往前移动一格。如果不是退格符，则执行 uartputc_sync 将字符输出void uartputc_sync(int c)能够以不中断的情况下，通过轮询等待串口空闲时，向串口发送字符 调用 `put_off` 关闭中断，循环 `ReadReg(LSR)` 读取 (Transmit Holding Empty，LSR_TX_IDLE)为空 表示串口能够接收字符了，调用 `WriteReg(THR, c)` 写入到 THR 寄存器之中，最后 调用 `pop_off()` 开启中断。cons 结构体一个专门用于 console 的锁定义输入字符大小为 128，char 类型buf，还有三个读 r、写 w、编辑 e 的参数int consolewrite(int user_src, uint64 src, int n)user_src 参数应该是01来表示是否来源于用户空间src 参数表示来源地址n 参数表示大小利用for 循环 调用 either_copyin 函数，每个for循环得到一个字符，然后调用 consputc 函数返回 写入的字符个数int consoleread(int user_dst, uint64 dst, int n)该函数 输入 n 个字符到 用户空间的目标位置 user_dst只要 cons.r == cons.w 时，sleep(&amp;cons.r, &amp;cons.lock)c = cons.buf[cons.r++ % INPUT_BUF_SIZE]; 读取缓冲区字符当 c == C('D') 时，C('D') 表示 Ctrl+D 的 ASCII 值，文件结束的标志，要结束调用 either_copyout 将字符 复制到 目标用户空间中每次成功复制 dst++; –n; 直到 n为0如果是换行符 \\n 则 break跳出最后返回 读取的字符数void consoleintr(int c)控制台中断处理程序case C('P'): // Print process list. 通过 procdump() 打印进程列表（打印出每个进程的id、状态以及名字）case C('U'): // Kill line. 一直删除字符，直到 \\n case C('H'): // Backspace case '\\x7f': // Delete key 删除最后一个字符default: 使用 consputc(c) 回显到用户界面，存储到控制台缓存中，并且如果是要结束一行或者输入缓冲区已满，则唤醒控制台读取进程。void consoleinit(void)调用 uartinit 初始化uart并初始 devsw[console].read 和 devsw[console].write 对应上 控制台输入和控制台输出函数" }, { "title": "xv6 源码解析 - kerneltrap函数", "url": "/posts/xv6-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-kerneltrap%E5%87%BD%E6%95%B0/", "categories": "计算机", "tags": "操作系统/6S081/源码解析", "date": "2024-01-21 02:34:00 +0000", "snippet": "#操作系统/6S081/源码解析code// interrupts and exceptions from kernel code go here via kernelvec,// on whatever the current kernel stack is.void kerneltrap(){ int which_dev = 0; uint64 sepc = r_sepc(); u...", "content": "#操作系统/6S081/源码解析code// interrupts and exceptions from kernel code go here via kernelvec,// on whatever the current kernel stack is.void kerneltrap(){ int which_dev = 0; uint64 sepc = r_sepc(); uint64 sstatus = r_sstatus(); uint64 scause = r_scause(); if((sstatus &amp; SSTATUS_SPP) == 0) panic(\"kerneltrap: not from supervisor mode\"); if(intr_get() != 0) panic(\"kerneltrap: interrupts enabled\"); if((which_dev = devintr()) == 0){ printf(\"scause %p\\n\", scause); printf(\"sepc=%p stval=%p\\n\", r_sepc(), r_stval()); panic(\"kerneltrap\"); } // give up the CPU if this is a timer interrupt. if(which_dev == 2 &amp;&amp; myproc() != 0 &amp;&amp; myproc()-&gt;state == RUNNING) yield(); // the yield() may have caused some traps to occur, // so restore trap registers for use by kernelvec.S's sepc instruction. w_sepc(sepc); w_sstatus(sstatus);}解析读取并保存寄存器对应数据if((sstatus &amp; SSTATUS_SPP) == 0) 如果原先的状态为0，也就是用户态就有问题；要保证先前为监管者模式if(intr_get() != 0) 检查中断是否启用，需要保证系统 不能启用中断在保证中断被禁用后，我们要检查是否还有隐型的中断发生，通过 if((which_dev = devintr()) == 0) 判断（2为时钟中断，1为其它中断，0为未识别的中断），如果是未识别的中断，那么报错if(which_dev == 2 &amp;&amp; myproc() != 0 &amp;&amp; myproc()-&gt;state == RUNNING) 如果是时钟中断，并且当前进程可用，那么 调用 yield() 函数，放弃CPU进行一轮调度那么在调度的时候，可能会有陷阱的发生，存储pc跟status状态的寄存器可能被覆盖了，所以要重新将一开始存储的数据恢复总结我认为这个函数对于系统调用是保证系统稳定性的一个过程" }, { "title": "xv6 源码解析 - vmcreate 函数", "url": "/posts/xv6-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-vmcreate-%E5%87%BD%E6%95%B0/", "categories": "计算机", "tags": "操作系统/6S081/源码解析", "date": "2024-01-20 02:34:00 +0000", "snippet": "#操作系统/6S081/源码解析code // create an empty user page table. // returns 0 if out of memory. pagetable_t uvmcreate() { pagetable_t pagetable; pagetable = (pagetable_t) kalloc(); if(pagetab...", "content": "#操作系统/6S081/源码解析code // create an empty user page table. // returns 0 if out of memory. pagetable_t uvmcreate() { pagetable_t pagetable; pagetable = (pagetable_t) kalloc(); if(pagetable == 0) return 0; memset(pagetable, 0, PGSIZE); return pagetable; }解析函数流程通过调用 kalloc 函数获取到没有被使用到的物理内存，并强制类型转换成 pagetable_t，并作为返回值返回需要多思考的点函数分配的内容大小为 4096 bytes 但是能够充当 页表目录，也能够当做某进程的物理内存来使用涉及到的代码[[xv6 源码解析 - kalloc 函数]][[xv6 源码解析 - pagetable_t]]" }, { "title": "xv6 源码解析 - usertrap 函数", "url": "/posts/xv6-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-usertrap-%E5%87%BD%E6%95%B0/", "categories": "计算机", "tags": "操作系统/6S081/源码解析", "date": "2024-01-20 02:34:00 +0000", "snippet": "#操作系统/6S081/源码解析code // // handle an interrupt, exception, or system call from user space. // called from trampoline.S // void usertrap(void) { int which_dev = 0; if((r_sstatus() &amp;...", "content": "#操作系统/6S081/源码解析code // // handle an interrupt, exception, or system call from user space. // called from trampoline.S // void usertrap(void) { int which_dev = 0; if((r_sstatus() &amp; SSTATUS_SPP) != 0) panic(\"usertrap: not from user mode\"); // send interrupts and exceptions to kerneltrap(), // since we're now in the kernel. w_stvec((uint64)kernelvec); struct proc *p = myproc(); // save user program counter. p-&gt;trapframe-&gt;epc = r_sepc(); if(r_scause() == 8){ // system call if(p-&gt;killed) exit(-1); // sepc points to the ecall instruction, // but we want to return to the next instruction. p-&gt;trapframe-&gt;epc += 4; // an interrupt will change sstatus &amp;c registers, // so don't enable until done with those registers. intr_on(); syscall(); } else if((which_dev = devintr()) != 0){ // ok } else { printf(\"usertrap(): unexpected scause %p pid=%d\\n\", r_scause(), p-&gt;pid); printf(\" sepc=%p stval=%p\\n\", r_sepc(), r_stval()); p-&gt;killed = 1; } if(p-&gt;killed) exit(-1); // give up the CPU if this is a timer interrupt. if(which_dev == 2) yield(); usertrapret(); }解析首先获取当前的寄存器状态，观察SPP位是否为0（观察之前的状态是否为用户态），确认之前为用户态后继续更改 STVEC 寄存器w_stvec((uint64)kernelvec); 将kernelvec汇编标签写入到 stvec 寄存器中，该寄存器是专门用来存储中断和异常的向量表（向量表指的是一系列处理程序的地址）保存用户模式 pc 值然后获取当前进程，用 p-&gt;trapframe-&gt;epc 保存当前用户模式下的程序地址（保存的原因是 usertrap 中可能有进程切换，可能导致sepc被覆盖）判断if(r_scause() == 8) 如果当前的触发的原因是因为系统调用的话，\t先判断当前进程是否被杀死了，被杀死了就退出；将 p-&gt;trapframe-&gt;epc 的程序地址往前一个字节，让其返回时不是在进入的地址，而是进行地址的下一条指令；\t然后开启中断，这里开启中断的原因是为了保证在进入系统调用前，寄存器状态不会受到其它中断状态影响，在进入调用前开启是为了，在漫长的系统调用中，能够处理别的系统调用的发生else if((which_dev = devintr()) != 0) 如果识别的原因的话，跳过else 如果二者都不属于，是一个异常，故终止进程usertrapret(); 通过调用该函数返回到用户模式下设计的代码[[xv6 源码解析 - risc.h#sstatus_spp]]" }, { "title": "xv6 源码解析 - procinit 函数", "url": "/posts/xv6-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-procinit-%E5%87%BD%E6%95%B0/", "categories": "计算机", "tags": "操作系统/6S081/源码解析", "date": "2024-01-20 02:34:00 +0000", "snippet": "#操作系统/6S081/源码解析code // kernel/proc.c // initialize the proc table at boot time. void procinit(void) { struct proc *p; initlock(&amp;pid_lock, \"nextpid\"); for(p = proc; p &lt; &am...", "content": "#操作系统/6S081/源码解析code // kernel/proc.c // initialize the proc table at boot time. void procinit(void) { struct proc *p; initlock(&amp;pid_lock, \"nextpid\"); for(p = proc; p &lt; &amp;proc[NPROC]; p++) { initlock(&amp;p-&gt;lock, \"proc\"); // Allocate a page for the process's kernel stack. // Map it high in memory, followed by an invalid // guard page. char *pa = kalloc(); if(pa == 0) panic(\"kalloc\"); uint64 va = KSTACK((int) (p - proc)); kvmmap(va, (uint64)pa, PGSIZE, PTE_R | PTE_W); p-&gt;kstack = va; } kvminithart(); }解析函数调用地点在 main.c 中被调用，在内核初始化完，调用 procinit 函数进行映射逻辑为每个进程分配一个 4096 的物理地址，作为内核栈为什么分配内核栈需要不同的虚拟地址呢因为为了防止相同的虚拟地址映射，也为了保证隔离性和安全性；内核的虚拟地址映射都是映射在 同一个内核空间中。" }, { "title": "xv6 源码解析 - kernelvec 汇编标签", "url": "/posts/xv6-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-kernelvec-%E6%B1%87%E7%BC%96%E6%A0%87%E7%AD%BE/", "categories": "计算机", "tags": "操作系统/6S081/源码解析", "date": "2024-01-20 02:34:00 +0000", "snippet": "#操作系统/6S081/源码解析code # # interrupts and exceptions while in supervisor # mode come here. # # push all registers, call kerneltrap(), restore, return. ...", "content": "#操作系统/6S081/源码解析code # # interrupts and exceptions while in supervisor # mode come here. # # push all registers, call kerneltrap(), restore, return. # .globl kerneltrap .globl kernelvec .align 4 kernelvec: // make room to save registers. addi sp, sp, -256 // save the registers. sd ra, 0(sp) sd sp, 8(sp) sd gp, 16(sp) sd tp, 24(sp) sd t0, 32(sp) sd t1, 40(sp) sd t2, 48(sp) sd s0, 56(sp) sd s1, 64(sp) sd a0, 72(sp) sd a1, 80(sp) sd a2, 88(sp) sd a3, 96(sp) sd a4, 104(sp) sd a5, 112(sp) sd a6, 120(sp) sd a7, 128(sp) sd s2, 136(sp) sd s3, 144(sp) sd s4, 152(sp) sd s5, 160(sp) sd s6, 168(sp) sd s7, 176(sp) sd s8, 184(sp) sd s9, 192(sp) sd s10, 200(sp) sd s11, 208(sp) sd t3, 216(sp) sd t4, 224(sp) sd t5, 232(sp) sd t6, 240(sp) // call the C trap handler in trap.c call kerneltrap // restore registers. ld ra, 0(sp) ld sp, 8(sp) ld gp, 16(sp) // not this, in case we moved CPUs: ld tp, 24(sp) ld t0, 32(sp) ld t1, 40(sp) ld t2, 48(sp) ld s0, 56(sp) ld s1, 64(sp) ld a0, 72(sp) ld a1, 80(sp) ld a2, 88(sp) ld a3, 96(sp) ld a4, 104(sp) ld a5, 112(sp) ld a6, 120(sp) ld a7, 128(sp) ld s2, 136(sp) ld s3, 144(sp) ld s4, 152(sp) ld s5, 160(sp) ld s6, 168(sp) ld s7, 176(sp) ld s8, 184(sp) ld s9, 192(sp) ld s10, 200(sp) ld s11, 208(sp) ld t3, 216(sp) ld t4, 224(sp) ld t5, 232(sp) ld t6, 240(sp) addi sp, sp, 256 // return to whatever we were doing in the kernel. sret解析栈指针下移addi sp, sp, -256 将当前的栈指针往下移动256，腾出256的空间来保存寄存器存储通过 sd ，汇编指令将寄存器的值分别存储在栈的对应空间调用 kerneltrap加载通过 ld 汇编指令将之前存储的数据加载回寄存器中结束返回处理addi sp, sp, 256 将栈指针回到原来的指向最后通过 sret 返回" }, { "title": "xv6 源码解析 - allocproc 函数", "url": "/posts/xv6-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-allocproc-%E5%87%BD%E6%95%B0/", "categories": "计算机", "tags": "操作系统/6S081/源码解析", "date": "2024-01-20 02:34:00 +0000", "snippet": "#操作系统/6S081/源码解析code```C// Look in the process table for an UNUSED proc.// If found, initialize state required to run in the kernel,// and return with p-&gt;lock held.// If there are no free procs,...", "content": "#操作系统/6S081/源码解析code```C// Look in the process table for an UNUSED proc.// If found, initialize state required to run in the kernel,// and return with p-&gt;lock held.// If there are no free procs, or a memory allocation fails, return 0.static struct proc*allocproc(void){struct proc *p;for(p = proc; p &lt; &amp;proc[NPROC]; p++) { acquire(&amp;p-&gt;lock); if(p-&gt;state == UNUSED) { goto found; } else { release(&amp;p-&gt;lock); }}return 0;found:p-&gt;pid = allocpid();// Allocate a trapframe page.if((p-&gt;trapframe = (struct trapframe *)kalloc()) == 0){ release(&amp;p-&gt;lock); return 0;}// An empty user page table.p-&gt;pagetable = proc_pagetable(p);if(p-&gt;pagetable == 0){ freeproc(p); release(&amp;p-&gt;lock); return 0;}// Set up new context to start executing at forkret,// which returns to user space.memset(&amp;p-&gt;context, 0, sizeof(p-&gt;context));p-&gt;context.ra = (uint64)forkret;p-&gt;context.sp = p-&gt;kstack + PGSIZE;return p;}```解析函数逻辑从 64 个进程中找到一个没有被使用的函数，找到后 分配 进程号 pid，给这个进程的 trapframe 分配存储空间，再给这个进程分配进程页表，trapframe 结构这个结构用于在内核状态切换时，将用户态进程的当前状态进行保存到 trapframe 中，在内核处理完后，将用户态进程的状态进行恢复，所以专门为 这个状态分配了一个存储空间调用的函数[[xv6 源码解析 - proc_pagetable 函数]]" }, { "title": "xv6 console.c 文件代码解析", "url": "/posts/6.S081-lab3-pgtbl/", "categories": "计算机", "tags": "操作系统/6S081/源码解析", "date": "2024-01-05 02:34:00 +0000", "snippet": "#操作系统/6S081打印页表实验要求以及注意点 将每一级对应的页表映射打印输出出来，打印出每个 pte 对应的 物理地址 可以参照 freewalk 函数是怎么遍历三级页表找到最终的物理地址的 不要打印非法的pte，也就是没有分配的pte是不需要进行打印的 所需的源码理解[[xv6 源码解析 - pagetable_t]][[xv6 源码解析 - pte]]PTE2PA#defin...", "content": "#操作系统/6S081打印页表实验要求以及注意点 将每一级对应的页表映射打印输出出来，打印出每个 pte 对应的 物理地址 可以参照 freewalk 函数是怎么遍历三级页表找到最终的物理地址的 不要打印非法的pte，也就是没有分配的pte是不需要进行打印的 所需的源码理解[[xv6 源码解析 - pagetable_t]][[xv6 源码解析 - pte]]PTE2PA#define PTE2PA(pte) (((pte) &gt;&gt; 10) &lt;&lt; 12) 这是一个宏，作用是将 pte 转换成 物理地址pte 的后10位是对应的标志位，所以向后移10位将对应的标志位信息抹消掉，而向左移动12位的原因是为了跟 offset 的12位进行对齐（PTE - 44位物理地址 + 10位标志位 | PPN - 44位物理地址 + 12位offset）kfree将物理页释放掉，并返回到 空闲链表 头中walk()将通过传来的code```Cvoidvmprint(pagetable_t pagetable, int depth) {if (depth &gt;= 3) return;if (depth == 0)\tprintf(\"page table %p\\n\", pagetable);for (int i = 0; i &lt; 512; i++) {\tint d = depth;\tpte_t pte = pagetable[i];\tif (pte &amp; PTE_V) {\twhile (d--) {\t\tprintf(\".. \");\t}\tuint64 child = PTE2PA(pte);\tprintf(\"..%d: pte %p pa %p\\n\", i, pte, child);\tvmprint((pagetable_t)child, depth + 1);\t}}}```为什么打印出来的页表一个在他头一个在尾，并且为什么尾的根页表不是511而是255位于尾页表的是陷阱，并且实际上使用只用了38位，所以根页表最大在255\tc\tpage table 0x0000000087f6e000\t..0: pte 0x0000000021fda801 pa 0x0000000087f6a000\t.. ..0: pte 0x0000000021fda401 pa 0x0000000087f69000\t.. .. ..0: pte 0x0000000021fdac1f pa 0x0000000087f6b000\t.. .. ..1: pte 0x0000000021fda00f pa 0x0000000087f68000\t.. .. ..2: pte 0x0000000021fd9c1f pa 0x0000000087f67000\t..255: pte 0x0000000021fdb401 pa 0x0000000087f6d000\t.. ..511: pte 0x0000000021fdb001 pa 0x0000000087f6c000\t.. .. ..510: pte 0x0000000021fdd807 pa 0x0000000087f76000\t.. .. ..511: pte 0x0000000020001c0b pa 0x0000000080007000\t每个进程拥有自己的内核页表实验要点 在 struct proc 为每个进程添加一个物理页表 生成一个新的页表给进程（在 allocproc 函数中） 确保每个进程的内核页表映射进程的内核栈（内核栈的设置都在 proinit 中，我们可以将其移动到 allocproc 中实现） 在 scheduler 函数中调用 在没有进程运行时，scheduler 函数 应该使用原本的 kernel_pagetable 释放进程的内核页表在 freeproc 需要另一种方式释放内核页表，同时不释放物理页 -疑问每个进程的内核栈还是要分配一个物理地址吧\t要给内核栈独立分配一个地址，不过映射在进程的内核页表上物理页不释放，到时候给谁用？不释放的原因 \t不能够释放进程内核页表 虚拟内存 对应的 物理内存，因为会将内核的物理内存给释放掉code##### `kernel/vm.c````c// kernel/vm.cpagetable_tkvm_map_kernalpagetable() {pagetable_t pgtbl = (pagetable_t) kalloc();memset(pgtbl, 0, PGSIZE);// uart registerskvmmap(pgtbl, UART0, UART0, PGSIZE, PTE_R | PTE_W);// virtio mmio disk interfacekvmmap(pgtbl, VIRTIO0, VIRTIO0, PGSIZE, PTE_R | PTE_W);// CLINTkvmmap(pgtbl, CLINT, CLINT, 0x10000, PTE_R | PTE_W);// PLICkvmmap(pgtbl, PLIC, PLIC, 0x400000, PTE_R | PTE_W);// map kernel text executable and read-only.kvmmap(pgtbl, KERNBASE, KERNBASE, (uint64)etext-KERNBASE, PTE_R | PTE_X);// map kernel data and the physical RAM we'll make use of.kvmmap(pgtbl, (uint64)etext, (uint64)etext, PHYSTOP-(uint64)etext, PTE_R | PTE_W);// map the trampoline for trap entry/exit to// the highest virtual address in the kernel.kvmmap(pgtbl, TRAMPOLINE, (uint64)trampoline, PGSIZE, PTE_R | PTE_X);return pgtbl;}voidkvminit(){kernel_pagetable = kvm_map_kernalpagetable();}voidkvmmap(pagetable_t pgtbl, uint64 va, uint64 pa, uint64 sz, int perm)uint64kvmpa(pagetable_t pgtbl, uint64 va)voiduvmunmap(pagetable_t pagetable, uint64 va, uint64 npages, int do_free)voidkvm_free_mapping(pagetable_t pgtbl) {for (int i = 0; i &lt; 512; i++) {\tpte_t pte = pgtbl[i];\tif ((pte &amp; PTE_V) &amp;&amp; (pte &amp; (PTE_R | PTE_W)) == 0) {\tuint64 child = PTE2PA(pte);\tkvm_free_mapping((pagetable_t)child);\tpgtbl[i] = 0;\t}}kfree((void*) pgtbl);}```##### `kernel/proc.c````Cvoidprocinit(void){struct proc *p;initlock(&amp;pid_lock, \"nextpid\");for(p = proc; p &lt; &amp;proc[NPROC]; p++) {\tinitlock(&amp;p-&gt;lock, \"proc\");\t// delete \t\t// char *pa = kalloc();\t// if(pa == 0)\t// panic(\"kalloc\");\t// uint64 va = KSTACK((int) (p - proc));\t// kvmmap(va, (uint64)pa, PGSIZE, PTE_R | PTE_W);\t// p-&gt;kstack = va;\t\t// delete}kvminithart();}static struct proc*allocproc(void) {// ...// An empty user page table.p-&gt;pagetable = proc_pagetable(p);if(p-&gt;pagetable == 0){\tfreeproc(p);\trelease(&amp;p-&gt;lock);\treturn 0;}// insert startchar *pa = kalloc();if (pa == 0) {\tpanic(\"kalloc\");}uint64 va = KSTACK(0);p-&gt;kernel_pagetable = kvm_map_kernalpagetable();kvmmap(p-&gt;kernel_pagetable, va, (uint64)pa, PGSIZE, PTE_R|PTE_W);p-&gt;kstack = va;// insert overmemset(&amp;p-&gt;context, 0, sizeof(p-&gt;context));p-&gt;context.ra = (uint64)forkret;p-&gt;context.sp = p-&gt;kstack + PGSIZE;return p;}static voidfreeproc(struct proc *p){if(p-&gt;trapframe)\tkfree((void*)p-&gt;trapframe);p-&gt;trapframe = 0;if(p-&gt;pagetable)\tproc_freepagetable(p-&gt;pagetable, p-&gt;sz);p-&gt;pagetable = 0;p-&gt;sz = 0;p-&gt;pid = 0;p-&gt;parent = 0;p-&gt;name[0] = 0;p-&gt;chan = 0;p-&gt;killed = 0;p-&gt;xstate = 0;// insert startkfree((void*)kvmpa(p-&gt;kernel_pagetable, p-&gt;kstack));p-&gt;kstack = 0;kvm_free_mapping(p-&gt;kernel_pagetable);p-&gt;kernel_pagetable = 0;// insert overp-&gt;state = UNUSED;}voidscheduler(void){struct proc *p;struct cpu *c = mycpu();c-&gt;proc = 0;for(;;){\t// Avoid deadlock by ensuring that devices can interrupt.\tintr_on();\t\tint found = 0;\tfor(p = proc; p &lt; &amp;proc[NPROC]; p++) {\tacquire(&amp;p-&gt;lock);\tif(p-&gt;state == RUNNABLE) {\t\tp-&gt;state = RUNNING;\t\tc-&gt;proc = p;\t\t\t\t// insert start\t\tw_satp(MAKE_SATP(p-&gt;kernel_pagetable));\t\tsfence_vma();\t\t// insert over\t\t\t\tswtch(&amp;c-&gt;context, &amp;p-&gt;context);\t\t\t\t// insert start\t\tkvminithart();\t\t//insert over\t\tc-&gt;proc = 0;\t\tfound = 1;\t}\trelease(&amp;p-&gt;lock);\t}#if !defined (LAB_FS)\tif(found == 0) {\tintr_on();\tasm volatile(\"wfi\");\t}#else\t;#endif}}```简化 copyin copyinstr实验要点 要从用户页表跟进程的内核页表中添加映射，让内核直接从内核页表中读取对应的数据 xv6 的用户地址从0往上，而内核地址从较高的地址开始；要限制用户地址小于内核地址的最小值 内核的最小地址是 PLIC 寄存器，值为 0xC000000，需要防止地址超过 0xC000000 在内核映射用户地址操作时，别忘了在每个更改进程映射的点上都要更改内核页表 不要忘了将 userinit 第一个进程中的内核用户页表包含在其内核页表中 在内核模式中，内核不能够访问 PTE_U （只有用户模式才能够访问） - 内核页表与物理内存的映射图 ![[xv6 内核页表与物理内存的映射图.png]] 根本理解 映射函数在这个实验中，最重要的是对于用户进程映射到内核页表中的理解；实际上，在进程的内核页表映射着用户进程的物理地址code##### `kernel/vm.c````cpagetable_tkvm_map_kernalpagetable() {pagetable_t pgtbl = (pagetable_t) kalloc();memset(pgtbl, 0, PGSIZE);// uart registerskvmmap(pgtbl, UART0, UART0, PGSIZE, PTE_R | PTE_W);// virtio mmio disk interfacekvmmap(pgtbl, VIRTIO0, VIRTIO0, PGSIZE, PTE_R | PTE_W);=-=// // CLINT// kvmmap(pgtbl, CLINT, CLINT, 0x10000, PTE_R | PTE_W);=-=// PLICkvmmap(pgtbl, PLIC, PLIC, 0x400000, PTE_R | PTE_W);// map kernel text executable and read-only.kvmmap(pgtbl, KERNBASE, KERNBASE, (uint64)etext-KERNBASE, PTE_R | PTE_X);// map kernel data and the physical RAM we'll make use of.kvmmap(pgtbl, (uint64)etext, (uint64)etext, PHYSTOP-(uint64)etext, PTE_R | PTE_W);// map the trampoline for trap entry/exit to// the highest virtual address in the kernel.kvmmap(pgtbl, TRAMPOLINE, (uint64)trampoline, PGSIZE, PTE_R | PTE_X);return pgtbl;}voidkvminit(){kernel_pagetable = kvm_map_kernalpagetable();=-=-// CLINTkvmmap(kernel_pagetable, CLINT, CLINT, 0x10000, PTE_R | PTE_W);-=-=}=-=-voidkvm_free_mapping(pagetable_t pgtbl) {for (int i = 0; i &lt; 512; i++) {\tpte_t pte = pgtbl[i];\tif ((pte &amp; PTE_V) &amp;&amp; (pte &amp; (PTE_R | PTE_W)) == 0) {\tuint64 child = PTE2PA(pte);\tkvm_free_mapping((pagetable_t)child);\tpgtbl[i] = 0;\t}}kfree((void*) pgtbl);}intkvm_copy_mapping(pagetable_t src, pagetable_t dst, int start, int sz) {pte_t *pte;uint64 pa, i;uint flags;for(i = PGROUNDUP(start); i &lt; sz; i += PGSIZE){\tif((pte = walk(src, i, 0)) == 0)\tpanic(\"kvm_copy_mapping: pte should exist\");\tif((*pte &amp; PTE_V) == 0)\tpanic(\"kvm_copy_mapping: page not present\");\tpa = PTE2PA(*pte);\tflags = PTE_FLAGS(*pte) &amp; ~PTE_U;\t\tif(mappages(dst, i, PGSIZE, pa, flags) != 0){\tgoto err;\t}}return 0;err:uvmunmap(dst, PGROUNDUP(start), (i - PGROUNDUP(start)) / PGSIZE, 0);return -1;}uint64kvmdealloc(pagetable_t pagetable, uint64 oldsz, uint64 newsz){if(newsz &gt;= oldsz)\treturn oldsz;if(PGROUNDUP(newsz) &lt; PGROUNDUP(oldsz)){\tint npages = (PGROUNDUP(oldsz) - PGROUNDUP(newsz)) / PGSIZE;\tuvmunmap(pagetable, PGROUNDUP(newsz), npages, 0);}return newsz;}-=-=```##### `kernel/exec.c````cintexec(char *path, char **argv){char *s, *last;int i, off;uint64 argc, sz = 0, sp, ustack[MAXARG+1], stackbase;struct elfhdr elf;struct inode *ip;struct proghdr ph;pagetable_t pagetable = 0, oldpagetable;struct proc *p = myproc();begin_op();if((ip = namei(path)) == 0){\tend_op();\treturn -1;}ilock(ip);// Check ELF headerif(readi(ip, 0, (uint64)&amp;elf, 0, sizeof(elf)) != sizeof(elf))\tgoto bad;if(elf.magic != ELF_MAGIC)\tgoto bad;if((pagetable = proc_pagetable(p)) == 0)\tgoto bad;// Load program into memory.for(i=0, off=elf.phoff; i&lt;elf.phnum; i++, off+=sizeof(ph)){\tif(readi(ip, 0, (uint64)&amp;ph, off, sizeof(ph)) != sizeof(ph))\tgoto bad;\tif(ph.type != ELF_PROG_LOAD)\tcontinue;\tif(ph.memsz &lt; ph.filesz)\tgoto bad;\tif(ph.vaddr + ph.memsz &lt; ph.vaddr)\tgoto bad;\tuint64 sz1;\tif((sz1 = uvmalloc(pagetable, sz, ph.vaddr + ph.memsz)) == 0)\tgoto bad;=-=-\tif (sz1 &gt;= PLIC)\tgoto bad;-=-=\tsz = sz1;\tif(ph.vaddr % PGSIZE != 0)\tgoto bad;\tif(loadseg(pagetable, ph.vaddr, ip, ph.off, ph.filesz) &lt; 0)\tgoto bad;}iunlockput(ip);end_op();ip = 0;p = myproc();uint64 oldsz = p-&gt;sz;// Allocate two pages at the next page boundary.// Use the second as the user stack.sz = PGROUNDUP(sz);uint64 sz1;if((sz1 = uvmalloc(pagetable, sz, sz + 2*PGSIZE)) == 0)\tgoto bad;sz = sz1;uvmclear(pagetable, sz-2*PGSIZE);sp = sz;stackbase = sp - PGSIZE;// Push argument strings, prepare rest of stack in ustack.for(argc = 0; argv[argc]; argc++) {\tif(argc &gt;= MAXARG)\tgoto bad;\tsp -= strlen(argv[argc]) + 1;\tsp -= sp % 16; // riscv sp must be 16-byte aligned\tif(sp &lt; stackbase)\tgoto bad;\tif(copyout(pagetable, sp, argv[argc], strlen(argv[argc]) + 1) &lt; 0)\tgoto bad;\tustack[argc] = sp;}ustack[argc] = 0;// push the array of argv[] pointers.sp -= (argc+1) * sizeof(uint64);sp -= sp % 16;if(sp &lt; stackbase)\tgoto bad;if(copyout(pagetable, sp, (char *)ustack, (argc+1)*sizeof(uint64)) &lt; 0)\tgoto bad;// arguments to user main(argc, argv)// argc is returned via the system call return// value, which goes in a0.p-&gt;trapframe-&gt;a1 = sp;// Save program name for debugging.for(last=s=path; *s; s++)\tif(*s == '/')\tlast = s+1;safestrcpy(p-&gt;name, last, sizeof(p-&gt;name));=-=-uvmunmap(p-&gt;kernel_pagetable, 0, PGROUNDUP(oldsz) / PGSIZE, 0);kvm_copy_mapping(pagetable, p-&gt;kernel_pagetable, 0, sz);-=-=// Commit to the user image.oldpagetable = p-&gt;pagetable;p-&gt;pagetable = pagetable;p-&gt;sz = sz;p-&gt;trapframe-&gt;epc = elf.entry; // initial program counter = mainp-&gt;trapframe-&gt;sp = sp; // initial stack pointerproc_freepagetable(oldpagetable, oldsz);vmprint(p-&gt;pagetable, 0);return argc; // this ends up in a0, the first argument to main(argc, argv)bad:if(pagetable)\tproc_freepagetable(pagetable, sz);if(ip){\tiunlockput(ip);\tend_op();}return -1;}```##### `kernel/proc.c````cvoiduserinit(void){struct proc *p;p = allocproc();initproc = p;// allocate one user page and copy init's instructions// and data into it.uvminit(p-&gt;pagetable, initcode, sizeof(initcode));p-&gt;sz = PGSIZE;=-=-kvm_copy_mapping(p-&gt;pagetable, p-&gt;kernel_pagetable, 0, p-&gt;sz);-=-=// prepare for the very first \"return\" from kernel to user.p-&gt;trapframe-&gt;epc = 0; // user program counterp-&gt;trapframe-&gt;sp = PGSIZE; // user stack pointersafestrcpy(p-&gt;name, \"initcode\", sizeof(p-&gt;name));p-&gt;cwd = namei(\"/\");p-&gt;state = RUNNABLE;release(&amp;p-&gt;lock);}intgrowproc(int n){uint sz;struct proc *p = myproc();sz = p-&gt;sz;if(n &gt; 0){\tint sz1;\tif((sz1 = uvmalloc(p-&gt;pagetable, sz, sz + n)) == 0) {\treturn -1;\t}\t=-=-\tif (kvm_copy_mapping(p-&gt;pagetable, p-&gt;kernel_pagetable, sz, sz + n)) {\treturn -1;\t}\t-=-=\tsz = sz1;} else if(n &lt; 0){=-=-\tuvmdealloc(p-&gt;pagetable, sz, sz + n);\tsz = kvmdealloc(p-&gt;kernel_pagetable, sz, sz + n);\t-=-=}p-&gt;sz = sz;return 0;}intfork(void){int i, pid;struct proc *np;struct proc *p = myproc();// Allocate process.if((np = allocproc()) == 0){\treturn -1;}=-=-// Copy user memory from parent to child.if(uvmcopy(p-&gt;pagetable, np-&gt;pagetable, p-&gt;sz) &lt; 0 ||\tkvm_copy_mapping(np-&gt;pagetable, np-&gt;kernel_pagetable, 0, p-&gt;sz) &lt; 0){-=-=\tfreeproc(np);\trelease(&amp;np-&gt;lock);\treturn -1;}np-&gt;sz = p-&gt;sz;np-&gt;parent = p;// copy saved user registers.*(np-&gt;trapframe) = *(p-&gt;trapframe);// Cause fork to return 0 in the child.np-&gt;trapframe-&gt;a0 = 0;// increment reference counts on open file descriptors.for(i = 0; i &lt; NOFILE; i++)\tif(p-&gt;ofile[i])\tnp-&gt;ofile[i] = filedup(p-&gt;ofile[i]);np-&gt;cwd = idup(p-&gt;cwd);safestrcpy(np-&gt;name, p-&gt;name, sizeof(p-&gt;name));pid = np-&gt;pid;np-&gt;state = RUNNABLE;release(&amp;np-&gt;lock);return pid;}```" }, { "title": "基于双缓冲区的日志系统", "url": "/posts/%E5%AE%9A%E6%97%B6%E5%99%A8%E5%B0%8F%E6%A0%B9%E5%A0%86%E5%AE%9E%E7%8E%B0/", "categories": "计算机", "tags": "语言/CPP", "date": "2023-04-17 02:34:00 +0000", "snippet": "#项目/WebServer/主从Reactor #语言/CPP小根堆代码实现std::priority_queue&lt;std::shared_ptr&lt;Timer&gt;, std::deque&lt;std::shared_ptr&lt;Timer&gt;&gt;,TimerCompare&gt; timer_heap_;该结构是 C++标准库中的一个数据结构，其底层实现是堆结构（...", "content": "#项目/WebServer/主从Reactor #语言/CPP小根堆代码实现std::priority_queue&lt;std::shared_ptr&lt;Timer&gt;, std::deque&lt;std::shared_ptr&lt;Timer&gt;&gt;,TimerCompare&gt; timer_heap_;该结构是 C++标准库中的一个数据结构，其底层实现是堆结构（树状的队列结构），小根堆跟大根堆的区别是 小根堆的父节点的数值永远小于其子节点，大根堆相反 父节点的数值永远大于其子节点为什么不使用大根堆因为使用小根堆的话，最快超时的定时器就在二叉堆的最顶部，要对它处理时直接在O(1)的耗时就处理完成了在插入和删除元素时，同样只是需要在O(log n)的时间复杂度就能够完成处理定时器用来定时什么通过小根堆进行定时，将超时时间最近（也就是最小的），放在堆顶，堆顶的定时器超时了，那么将HTTP连接的文件描述符delete掉" }, { "title": "基于双缓冲区的日志系统", "url": "/posts/%E5%9F%BA%E4%BA%8E%E5%8F%8C%E7%BC%93%E5%86%B2%E5%8C%BA%E7%9A%84%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/", "categories": "计算机", "tags": "语言/CPP", "date": "2023-04-17 02:34:00 +0000", "snippet": "#项目/WebServer/主从Reactor [[基于双缓冲区的日志系统.canvas|基于双缓冲区的日志系统]]这一个双缓冲区的日志系统，有三个大的模块组成，一个是每次调用日志时都会创建一个新的对象的logging模块，以及将保证数据流输入的logstream模块，还有一个由于buffer写入磁盘速度很慢，所有用异步同步的async模块。在当logging模块析构时，会将log_stre...", "content": "#项目/WebServer/主从Reactor [[基于双缓冲区的日志系统.canvas|基于双缓冲区的日志系统]]这一个双缓冲区的日志系统，有三个大的模块组成，一个是每次调用日志时都会创建一个新的对象的logging模块，以及将保证数据流输入的logstream模块，还有一个由于buffer写入磁盘速度很慢，所有用异步同步的async模块。在当logging模块析构时，会将log_stream中的数据存在一个内存变量中，然后将这个内存变量写到磁盘中，也就是用另一个类 调用异步同步将日志写入到磁盘中，LogStream 的内容写到了 AsyncLogging 缓冲区中后，在异步模块中，准备两个buffer，双缓冲技术的基本思路该日志系统场景为多生产者，单消费者的场景，多生产者将日志输入到缓冲区中，单消费者将缓冲区的数据写到磁盘中去。数据结构采用双缓冲区的形式将日志中的数据传到磁盘中，那么是怎么使用双缓冲区的呢？简单来说就是创建好两个缓冲区A B，前端将数据发送到A中，磁盘从B中读取数据并清空，如果A中数据满了，则AB两个缓冲区进行交换；总之就是将多条日志消息组合成一个大的日志写入到磁盘中。buffer就是4000字节" }, { "title": "muduo 网络库并发框架设计与实现", "url": "/posts/muduo-%E7%BD%91%E7%BB%9C%E5%BA%93%E5%B9%B6%E5%8F%91%E6%A1%86%E6%9E%B6%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/", "categories": "计算机", "tags": "语言/CPP", "date": "2023-04-15 02:34:00 +0000", "snippet": "#语言/CPP #项目/WebServer/主从ReactorEventLoopone loop per thread 顾名思义每个线程只能有一个 EventLoop 对象，因此 EventLoop 的构造函数会检查当前线程是否已经创建了其他 EventLoop 对象，遇到错误就终止程序（LOG_FATAL)。主要功能是运行事件循环 EventLoop::loop()。EventLoop 对...", "content": "#语言/CPP #项目/WebServer/主从ReactorEventLoopone loop per thread 顾名思义每个线程只能有一个 EventLoop 对象，因此 EventLoop 的构造函数会检查当前线程是否已经创建了其他 EventLoop 对象，遇到错误就终止程序（LOG_FATAL)。主要功能是运行事件循环 EventLoop::loop()。EventLoop 对象的生命期通常和其所属的线程一样长，它不必是 heap 对象。event_loop的主要逻辑在muduo中，每个线程中都有一个循环去执行处理事件，所以不管 主从Reactor 都是event_loop进行驱动的每个 EventLoop 对象都 唯⼀绑定了⼀个线程 ，这个线程其实就在⼀直执⾏这个函数⾥⾯的 while 循环，这个while 循环的⼤致逻辑⽐较简单。就是调⽤ Poller::poll() 函数获取事件监听器上的监听结果。接下来在Loop ⾥⾯就会调⽤监听结果中每⼀个 Channel 的处理函数 HandlerEvent() 。每⼀个 Channel 的处理函数会根据 Channel 中封装的实际发⽣的事件，执⾏ Channel 中封装的各事件处理函数。（⽐如⼀个 Channel 发⽣了可读事件，可写事件，则这个 Channel 的 HandlerEvent() 就会调⽤提前注册在这个 Channel 的可读事件和可写事件处理函数，⼜⽐如另⼀个 Channel 只发⽣了可读事件，那么 HandlerEvent() 就只会调⽤提前注册在这个 Channel 中的可读事件处理函数。从中可以看到，每个 EventLoop 实际上就做了四件事 epoll_wait阻塞 等待就绪事件(没有注册其他fd时，可以通过event_fd来异步唤醒) 处理每个就绪事件 执⾏正在等待的函数(fd注册到epoll内核事件表) 处理超时事件，到期了就从定时器⼩根堆中删除Channel class每个 Channel 对象自始至终只负责一个文件描述符（fd） 的 IO 事件分发，但它并不拥有这个 fd，也不会在析构的时候关闭这个 fd。Channel::handleEvent() 是 Channel 的核心，它由 EventLoop::loop() 调用，它 的功能是根据 revents_ 的值分别调用不同的用户回调。 Channel类实际上就是将 文件描述符进行了封装，主要属性有 文件描述符 fd 、当前正在监听的事件 events 、返回的就绪的事件 revents 、 上一次的事件 last_events设置回调函数提供给 文件描述符 设置 读、写、更新、错误 时调用的回调函数，以及 当执行 读、写、更新、错误 的 回调函数，还有一个专门更新 事件的 revents 的信号执行对应行为的 HandleEvents() 函数，在这个函数中会根据信号跳转指定对应行为的函数Poller classmuduo 同时支持 poll(2) 和 epoll(4) 两种 IO multiplexing 机制。Poller 是 EventLoop 的间接成员，只供其 owner EventLoop 在 IO 线程调用，因此无须加锁。其生命期与 EventLoop 相等。poller 类中 主要实现了将 epoll 中 文件描述符的 添加、修改和执行操作 做了一系列的封装在初始化对象的 epoll_fd 时，使用的是 epoll_create1(EPOLL_CLOEXEC) 实现 确保不需要时，将其关闭，避免资源泄露和程序的健壮性。EPOLLADD将传过来的 channel 中的文件描述符和事件添加到 内核事件表中，并且若是传入的超时时间大于0，则为该文件描述符绑定定时器。poll()封装了 epoll_wait() 函数的一系列操作，将监听到的文件描述符都放到 ready_channels 文件描述符数组中Reactor核心时序图" }, { "title": "Linux IO多路复用", "url": "/posts/Linux-IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/", "categories": "计算机", "tags": "语言/CPP", "date": "2023-04-14 02:34:00 +0000", "snippet": "#项目/WebServer #语言/CPP三种常用IO的原理select由 bitmap 存储文件描述符，当要知道是否是有事件发生时，将 文件描述符集合 从用户态拷贝到内核中，然后内核通过遍历的形式检查是否有事件发生，如果有事件产生，将此文件描述符标记为 可读 或者 可写，接着将文件描述符集合拷贝回用户态，再通过遍历集合的方式找到可读或者可写的文件描述符进行处理。所以使用 select 方法...", "content": "#项目/WebServer #语言/CPP三种常用IO的原理select由 bitmap 存储文件描述符，当要知道是否是有事件发生时，将 文件描述符集合 从用户态拷贝到内核中，然后内核通过遍历的形式检查是否有事件发生，如果有事件产生，将此文件描述符标记为 可读 或者 可写，接着将文件描述符集合拷贝回用户态，再通过遍历集合的方式找到可读或者可写的文件描述符进行处理。所以使用 select 方法每次调用都需要进行 两次 文件描述符集合的拷贝和两次文件描述符集合的遍历pollpoll方法跟select方法没有什么区别，只是在存放文件描述符集合的数据结构使用了链表的方式，这样的好处是对于存放的文件描述符数量没有了限制select 跟 poll 方式随着 并发数 上来，性能的损耗会呈指数级增长。epollepoll用法epoll_create 创建一个 epoll对象 epfd，再通过 epoll_ctl 将需要监视的 socket 添加到epfd中，最后调用 epoll_wait 等待数据底层执行过程通过 红黑树 在 内核中 维护文件描述符集合，这样的增删查的时候的效率为O(logn)，当文件描述符有事件发生时，就会将有事件的文件描述符加入到 就绪链表 中，可以通过epoll_wait调用返回。![[Pasted image 20230910124118.png]]epoll 主要的开销就在 添加文件描述符 epoll_ctl 进行系统调用的时候为什么系统调用开销大呢因为系统调用涉及到 上下文转换 和 用户态与内核态之间 的切换边缘触发模式 与 水平触发模式区别 使用边缘触发模式时，当被监控的 Socket 描述符上有可读事件发生时，服务器端只会从 epoll_wait 中苏醒一次，并且一次性将内核缓冲区的数据读取完 触发条件： 1. 低电平 =&gt; 高电平 2. 高电平 =&gt; 高电平 使用水平触发模式时，当被监控的 Socket 描述符上有可读事件发生时，服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束 触发条件： 1. 低电平 =&gt; 高电平关于 触发结束对于一个非阻塞 socket，如果使用 epoll 边缘模式去检测数据是否可读，触发可读事件以后，一定要一次性把 socket 上的数据收取干净才行，也就是一定要循环调用 recv 函数直到 recv 出错，错误码是 EWOULDBLOCK（EAGAIN 一样）；如果使用水平模式，则不用，你可以根据业务一次性收取固定的字节数，或者收完为止。为什么边缘触发一定要与非阻塞IO一起使用？因为边缘触发模式需要程序会一直执行 I/O 操作，直到系统调用（如 read 和 write）返回错误，错误类型为 EAGAIN 或 EWOULDBLOCK（找到没有数据为止）。如下是边缘触发模式下收取数据的代码： C++ bool TcpSession::RecvEtMode() { //每次只收取256个字节 char buff[256]; while (true) { int nRecv = ::recv(clientfd_, buff, 256, 0); if (nRecv == -1) { if (errno == EWOULDBLOCK) return true; else if (errno == EINTR) continue; return false; } //对端关闭了socket else if (nRecv == 0) return false; inputBuffer_.add(buff, (size_t)nRecv); } return true; } " }, { "title": "Webserver 数据库连接池实现", "url": "/posts/Webserver-%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E5%AE%9E%E7%8E%B0/", "categories": "计算机", "tags": "语言/CPP", "date": "2023-04-01 02:34:00 +0000", "snippet": "#项目/WebServer/单Reactor连接池的实现是通过单例模式创建到一个对象，用RAII机制获取和释放连接维护 最大连接数、当前可用连接数 以及 当前已用连接数 三个变量 ^44fb65[[单例模式]]实现使用局部静态变量懒汉模式创建连接池static connection_pool *GetInstance();通过 GetInstance() 函数创建并返回一个连接池对象```C...", "content": "#项目/WebServer/单Reactor连接池的实现是通过单例模式创建到一个对象，用RAII机制获取和释放连接维护 最大连接数、当前可用连接数 以及 当前已用连接数 三个变量 ^44fb65[[单例模式]]实现使用局部静态变量懒汉模式创建连接池static connection_pool *GetInstance();通过 GetInstance() 函数创建并返回一个连接池对象```C++connection_pool *connection_pool::GetInstance() { static connection_pool connPool; return &amp;connPool;}```static表示程序只会在第一次调用 GetInstance() 函数时初始化，知道程序结束，所以程序中全局唯一的连接池对象[[RAII]]的实现connectionRAII 在创建后的构造函数直接调用 *SQL = connPool-&gt;GetConnection(); 获取数据库可用连接；然后RAII对象在局部函数结束后，自动调用析构函数，释放当前使用的连接。信号与锁GetConnection()获取可用连接时，等待信号量，对连接池进行加锁，获取连接完，当前可用连接数–，当前已用连接数++，处理完进行解锁ReleaseConnection(MYSQL *con)释放当前可用连接，加锁，将使用完的连接放到连接池中，当前可用连接数++，当前已用连接数–，处理完进行解锁DestroyPool()销毁数据库连接池，加锁，遍历连接池中每个连接，一个个进行关闭 mysql_close(con) ，最后connList.clear() 将连接池列表销毁，处理完进行解锁登陆耗时如何解决？由于 在目前的项目中，是将所有的用户名密码 load 到内存中，登陆时遍历，所以在数据量大的时候很非常耗时解决方案利用 hash 建立多级索引，加快用户的验证例如 有 10亿的用户信息，将用户信息进行缩小1000倍的hash，得到100万的hash数据，即一级用户的信息块，再将一级用户信息块再进行 hash ，最终得到1000的hash数据，即二级用户信息块。在这种方式下，系统只需要遍历一次1000个数据的二级用户信息块，找到对应的一级信息块，再找到最终对应的用户数据就可以了。" }, { "title": "复用模式详解", "url": "/posts/%E5%A4%8D%E7%94%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/", "categories": "计算机", "tags": "语言/CPP", "date": "2023-03-26 02:34:00 +0000", "snippet": "#项目/WebServerselect poll epoll得知有事件发生的区别 select 跟 poll 都是遍历整个文件描述符，去判断是否有活动； epoll 通过轮询机制监视文件描述符，当文件描述符有事件发生时，会自动触发 epoll 回调函数通知 epoll 文件描述符，然后将就绪的文件描述符放到 epoll 维护的 ready list 中，等待 epoll_wait 调用后...", "content": "#项目/WebServerselect poll epoll得知有事件发生的区别 select 跟 poll 都是遍历整个文件描述符，去判断是否有活动； epoll 通过轮询机制监视文件描述符，当文件描述符有事件发生时，会自动触发 epoll 回调函数通知 epoll 文件描述符，然后将就绪的文件描述符放到 epoll 维护的 ready list 中，等待 epoll_wait 调用后被处理底层结构的区别 select 是由线性表来描述 文件描述符的集合，文件描述符有上限 poll 是由链表描述 文件描述符的集合 epoll 的底层是红黑树，并且维护一个 ready_list （链表），其中包含着那些已就绪的事件它们各自的缺点 select 跟 poll 这两种复用方式，在调用的时候需要将文件描述符集合拷贝到内核态中； 并且只能应用于 LT水平触发模式 epoll 是将文件描述符集合维护在内核态中，但是添加文件描述时，需要执行一个系统调用而造成较大的开销； epoll 支持水平触发模式 跟 边缘触发模式 [[epoll_wait()函数]] 分别的应用场景 当监听的 文件描述符 数量较少，且单位时间内都比较活跃的情况下（频繁发生），使用 select 或 poll 当监听的 文件描述符 数量较多，且单位时间内仅部分活跃的情况下，使用 epoll两种触发模式LT（水平触发模式）一般来说水平触发模式类似select，LT会去遍历在epoll事件表中每个文件描述符，来观察是否有我们感兴趣的事件发生（也就是 是否处于活跃状态），如果有（触发了该文件描述符上的回调函数），epoll_wait就会以非阻塞的方式返回。该模式可以不立即处理新的事件，所以若该epoll事件没有被处理完（没有返回EWOULDBLOCK），该事件还会被后续的epoll_wait再次触发，继续读取未完成的数据。应用场景适合连接较少的场景，复杂度低且容器理解和使用LT实现通过 if 条件判断处理连接，且只处理一次连接请求，然后创建定时器\t本项目中其实只有在建立新连接的时候有用到LT，并主要体现在处理一次连接请求那，下次有新的请求再通过LT去处理ET（边缘触发模式）ET在发现有我们感兴趣的事件发生后，立即返回，并且使用非阻塞IO方式读取数据，直到数据全部读取完毕或者出现 EWOULDBLOCK 错误码。\t 在使用ET模式时，必须要保证该文件描述符是非阻塞的（确保在没有数据可读时，该文件描述符不会一直阻塞）；并且每次调用read和write的时候都必须等到它们返回EWOULDBLOCK（确保所有数据都已读完或写完）。应用场景适合连接较多的场景，在高并发场景下有更高的效率\t同样也是在建立新连接的时候用到了ET，并主要体现在一次读到底那ET 实现通过 while 循环来处理连接请求，因为边缘触发可能会同时接到多个连接请求，循环处理并分别创建定时器" }, { "title": "webserver中 利用链表存放定时器轮询关闭空闲线程", "url": "/posts/webserver%E4%B8%AD-%E5%88%A9%E7%94%A8%E9%93%BE%E8%A1%A8%E5%AD%98%E6%94%BE%E5%AE%9A%E6%97%B6%E5%99%A8%E8%BD%AE%E8%AF%A2%E5%85%B3%E9%97%AD%E7%A9%BA%E9%97%B2%E7%BA%BF%E7%A8%8B/", "categories": "计算机", "tags": "语言/CPP", "date": "2023-03-11 02:34:00 +0000", "snippet": "#项目/WebServer/单Reactor #语言/CPP定时器容器是一个带头尾结点的升序双向链表，并按照超时时间进行排序（超时时间短到长）构造函数为头尾节点赋nullptr析构函数将链表中每个节点delete掉添加定时器 如果定时器为空，直接返回 如果头节点为空，那么将定时器存入头尾节点 上两条件都不满足，那么将定时器按顺序插入到链表中 如果上三都不满足，那么定时器的超市时间比较...", "content": "#项目/WebServer/单Reactor #语言/CPP定时器容器是一个带头尾结点的升序双向链表，并按照超时时间进行排序（超时时间短到长）构造函数为头尾节点赋nullptr析构函数将链表中每个节点delete掉添加定时器 如果定时器为空，直接返回 如果头节点为空，那么将定时器存入头尾节点 上两条件都不满足，那么将定时器按顺序插入到链表中 如果上三都不满足，那么定时器的超市时间比较长，处于尾节点，进行特殊处理调整定时器当某个定时器发生变化的时候，调整定时器在链表中的位置 如果被调整的定时器在链表尾部或者仍然小于下一个定时器的超时值则直接返回 若为头结点或内部结点，则将定时器取出重新插入删除定时器 同时为头尾结点（当链表中只有一个定时器时） 为头结点时 为尾结点时 剩下则是内部结点定时处理函数计时进行轮询，因为链表里面的定时器是升序排列的，所以从上到下去遍历定时器，将到期的定时器调用[[回调函数]]，执行定时事件，并删除定时器的超时时间timer-&gt;expire = curTime + 3 * TIMESLOT (TIMESLOT = 5) 所以超时时间是15sadjust_timer 源码解析当收到读写操作时，更新定时器，将定时器的超时时间进行调整\t```C++\tvoid Webserver::adjust_timer(util_timer *timer)\t{\t\ttime_t cur = time(NULL);\t\ttimer-&gt;expire = cur + 3 * TIMESLOT;\t\tutils.m_timer_lst.adjust_timer(timer);\tLOG_INFO(\"%s\", \"adjust timer once\");}``` 将定时器在容器中的位置同样进行调整```C++void sort_timer_lst::adjust_timer(util_timer *timer) {\tif (!timer) {\t\treturn;\t}\tutil_timer *tmp = timer-&gt;next;\tif (!tmp || (timer-&gt;expire &lt; tmp-&gt;expire)) {\t\treturn;\t}\t// 当被调整的是头结点，将头结点取出，放入add_timer中\tif (timer == head) {\t\thead = head-&gt;next;\t\thead-&gt;prev = nullptr;\t\ttimer-&gt;next = nullptr;\t\tadd_timer(timer, head);\t}\telse {\t\ttimer-&gt;prev-&gt;next = timer-&gt;next;\t\ttimer-&gt;next-&gt;prev = timer-&gt;prev;\t\tadd_timer(timer, timer-&gt;next);\t}}```" }, { "title": "内存泄漏与C++", "url": "/posts/webserver%E4%BF%A1%E5%8F%B7/", "categories": "计算机", "tags": "语言/CPP", "date": "2023-03-10 02:34:00 +0000", "snippet": "#项目/WebServer/单Reactor #语言/CPPSIGTERM 信号当进程接收到 SIGTERM 信号时，将 标志是否关闭服务的标志位 置为true，结束循环addsig() 函数在webserver中加上特定的信号，不执行它们的默认操作（[[信号#执行默认操作跟执行信号的区别]]），而是要在项目中捕获到这个特定信号后，去处理相应的操作，在webserver中特别捕获了两个信号分...", "content": "#项目/WebServer/单Reactor #语言/CPPSIGTERM 信号当进程接收到 SIGTERM 信号时，将 标志是否关闭服务的标志位 置为true，结束循环addsig() 函数在webserver中加上特定的信号，不执行它们的默认操作（[[信号#执行默认操作跟执行信号的区别]]），而是要在项目中捕获到这个特定信号后，去处理相应的操作，在webserver中特别捕获了两个信号分别是 SIGALRM 跟 SIGSTERM定时发送 SIGALRM 信号```C++//定时处理任务，重新定时以不断触发SIGALRM信号void Utils::timer_handler(){\tm_timer_lst.tick();\talarm(m_TIMESLOT);}```目的是周期性的发送SIGALRM信号怎么处理在我的webserver项目中主要通过 addsig 函数关注两个信号 分别是 SIGALRM 跟 SIGTERM 信号，对这两个信号进行对应的处理，不让它们让我的项目执行 信号的默认操作，而是执行自定义的行为，分别是关闭定时器重新定时以及去将升序链表中的所有定时器进行一个处理 跟 关闭webserver操作" }, { "title": "内存泄漏与C++", "url": "/posts/%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E4%B8%8EC++/", "categories": "计算机", "tags": "语言/CPP", "date": "2023-02-26 02:34:00 +0000", "snippet": "#语言/CPP定义申请了一块内存空间，使用完毕后没有释放掉。它的表现是程序运行的时间越长，占用的内存越多，最终用尽全部内存。涉及到内存泄漏[[堆区和栈区的区别]]栈由编译器进⾏管理，在需要时由编译器⾃动分配空间，在不需要时候⾃动回收空间，⼀般保存的是局部变量和函数参数等。它是连续的空间，在函数调用的时候，首先入栈的是主函数的下一条可执行指令的地址，然后才是各个参数。⼤多数编译器中，参数是从右...", "content": "#语言/CPP定义申请了一块内存空间，使用完毕后没有释放掉。它的表现是程序运行的时间越长，占用的内存越多，最终用尽全部内存。涉及到内存泄漏[[堆区和栈区的区别]]栈由编译器进⾏管理，在需要时由编译器⾃动分配空间，在不需要时候⾃动回收空间，⼀般保存的是局部变量和函数参数等。它是连续的空间，在函数调用的时候，首先入栈的是主函数的下一条可执行指令的地址，然后才是各个参数。⼤多数编译器中，参数是从右向左⼊栈（原因在于采⽤这种顺序，是为了让程序员在使⽤ [[C++的“函数参数⻓度可变”特性]]时更⽅便。如果是从左向右压栈，第⼀个参数（即描述 可变参数表各变量类型的那个参数）将被放在栈底，由于可变参的函数第⼀步就需要解析可变参数表的各参数类型，即第⼀步就需要得到上述参数，因此，将它放在栈底是很不⽅便的。） 如果第一个参数在栈底，我们就需要遍历整个栈才能找到它，这样效率很低。而如果第一个参数在栈顶， 我们就可以直接访问它，然后根据它的信息来处理后面的参数栈是⾼地址向低地址扩展，栈底⾼地址，空间较⼩。堆由程序员管理，需要⼿动 [[C++ new delete 跟 malloc free]] 进⾏分配和回收，如果不进⾏回收的话，会造成[[内存泄漏]]的问题。分配方式它是不连续的空间，实际上系统中有⼀个空闲链表，当有程序申请的时候，系统遍历空闲链表找到 第⼀个⼤于等于申请⼤⼩的空间分配给程序，⼀般在分配空间的时候，也会在空间头部写⼊内存⼤⼩，⽅便 delete 回收空间⼤⼩。当然如果有剩余的，也会将剩余的插⼊到空闲链表中，这也是产⽣内存碎⽚的原因。堆是低地址向⾼地址扩展，空间较⼤，较为灵活。什么情况下使用堆区什么情况使用栈区一般情况下，当需要分配一块较小的内存且其大小是固定的，或者需要在函数调用期间使用的局部变量时，可以使用栈区分配内存。当需要分配一块较大的内存，或者需要在函数外部访问的变量时，应该使用堆区分配内存。但是，需要注意的是，在使用堆区分配内存时需要注意内存泄漏和内存泄漏问题，一旦内存泄漏发生，将导致系统的内存资源被耗尽，并可能导致程序崩溃。因此，在使用堆区分配内存时，应该小心谨慎，确保适当地释放内存以避免出现这些问题。[[C++ 智能指针]]智能指针的作用就是管理一个指针，避免程序员申请的空间在函数结束的时候忘记将释放掉，造成[[内存泄漏]]的发生形象来说，智能指针就是一个类，当超出这个类的时，就会自动调用析构函数自动释放资源。[[C++ new delete 跟 malloc free]]基本概念new/delete 是 运算符，malloc/free是 库函数，他们都可以在堆上分配和回收内存空间new 会调用 malloc 分配未初始化的内存空间，然后使用构造函数对空间进行初始化；delete 先使用析构函数对对象进行析构，然后再调用 free 回收内存空间而malloc的作用只能分配出未初始化的空间，free 只能回收释放内存空间 运算符 是编译器定义好的行为函数 是自包含的代码单元 总结对于非内部数据而言，光用 malloc/free 是不能够满足对象的需求，即在new分配空间的时候，帮助你自动执行构造函数，在delete释放空间的时候，帮你自动执行析构函数又因为 malloc/free 是库函数不是运算符，不在编译器的控制权限内，所以不能够把执行构造和析构的操作强加于 malloc/free 操作所以这就是为什么需要 new 跟 delete 运算符的原因手动创建跟释放资源的隐患通过 new/delete malloc/free 创建的空间都是在堆中 由程序员手动管理，如果在创建后不手动回收释放资源的话，就会导致[[内存泄漏]]的问题产生" }, { "title": "TCP四次挥手", "url": "/posts/TCP%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/", "categories": "计算机", "tags": "网络/TCP", "date": "2023-02-01 02:34:00 +0000", "snippet": "#网络/TCP概要当要进行断开连接时，连接的双方都可以通过四次握手将连接断开，断开连接后，主机的资源将被释放具体过程由于双方都可以发送连接，所以我将第一个发送FIN报文的一方称为发送方，另一方为接收方第一次挥手在发送方保证自己没有要处理和发送的数据后，向接收方发送FIN报文，之后发送方状态从 ESTABLISHED 状态转变为 FIN_WAIT1 状态第二次挥手接收方接收了发送来的FIN请求...", "content": "#网络/TCP概要当要进行断开连接时，连接的双方都可以通过四次握手将连接断开，断开连接后，主机的资源将被释放具体过程由于双方都可以发送连接，所以我将第一个发送FIN报文的一方称为发送方，另一方为接收方第一次挥手在发送方保证自己没有要处理和发送的数据后，向接收方发送FIN报文，之后发送方状态从 ESTABLISHED 状态转变为 FIN_WAIT1 状态第二次挥手接收方接收了发送来的FIN请求报文，同意后，向发送方发送ACK应答报文，因为可能还有数据要处理和发送，接收方状态从 ESTABLISHED 状态转变为 CLOSE_WAIT 的状态第三次挥手在接收方处理完数据后，向发送方发送FIN请求报文，状态从 CLOSE_WAIT 转变为 LAST_WAIT 状态第四次挥手发送方收到后，向接收方发送ACK应答报文，状态从 FIN_WAIT2 转变为 TIME_WAIT 状态，在2MSL时间后，状态自动转变为CLOSE接收方接收到发送方发来的应答报文，状态就从 LAST_WAIT 转变为 CLOSE 了深层问题什么情况会出现三次挥手呢首先要搞清楚什么是三次挥手，三次挥手就是将接收方发送的FIN报文跟ACK报文合并在一起发送那么什么情况会合并在一起发送呢首先不合并在一起发送是因为 FIN 报文的发送可能需要等待接收方的处理完数据在发送条件在数据处理完时以及开启了 TCP延迟确认机制 时就会出现三次挥手的情况发生TCP延迟确认机制因为在TCP报文中没有携带数据的ACK报文是低效的，比较浪费资源，所以有了这个TCP延迟确认机制尽量让数据跟ACK报文一起发送 当有数据要响应时，ACK会随着响应数据一起立刻发送给对方 当没有数据要响应，ACK报文就会等待一段时间，看有没有数据需要一起发送为什么接收方要有一个2MSL的 TIME_WAIT 状态为什么发送方在连接关闭时，需要有一个 TIME_WAIT 状态 为了防止历史连接中的数据，被相同四元组的连接 错误接收 保证接收方能够正确关闭连接为什么 TIME_WAIT 状态持续时间为 2MSLMSL的英文全称是 Maximum Segment Lifetime 就是一个报文的最大生存时间，也就是说报文一来一回所用的最长时间就是2MSL所以能够保证在发送方一次应答报文丢失，产生一次超时重传，来保证接收方连接的关闭为什么服务端出现大量的 close_wait 状态服务端如果要进行第三次握手，那么服务端需要调用 close() 函数所以出现这种情况的根本原因有两点： 服务端线程阻塞，导致无法调用close()函数 调用close()函数出现大量耗时的逻辑" }, { "title": "TCP三次握手", "url": "/posts/TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B/", "categories": "计算机", "tags": "网络/TCP", "date": "2023-02-01 02:34:00 +0000", "snippet": "#网络/TCP概要TCP的三次握手是一个建立连接所必要的一个连接流程，通过TCP的三次握手能够保证双方之间都具有接收和发送数据的能力连接过程握手前的准备一开始发送方的状态都为 CLOSE 状态，因为都是客户端发送连接，所以我将请求发送方称为客户端，请求接收方称为服务端。首先服务端会主动对某一个端口进行监听，服务端处于 LISTEN 状态第一次握手客户端会随机初始化序号 client_isn ...", "content": "#网络/TCP概要TCP的三次握手是一个建立连接所必要的一个连接流程，通过TCP的三次握手能够保证双方之间都具有接收和发送数据的能力连接过程握手前的准备一开始发送方的状态都为 CLOSE 状态，因为都是客户端发送连接，所以我将请求发送方称为客户端，请求接收方称为服务端。首先服务端会主动对某一个端口进行监听，服务端处于 LISTEN 状态第一次握手客户端会随机初始化序号 client_isn ，将此序号放到TCP首部的序号字段中，同时将 SYN 标志位 置为一，表示该报文为 SYN 报文，随后服务器为 SYN-SENT 状态第二次握手服务端接收到客户端发来的请求报文后，首先服务端也随机初始化自己的序号 server_isn 放到TCP首部的序号字段中，并将TCP首部的确认应答字段填入 client_isn+1，接着把SYN跟ACK置为一，随后服务端处于SYN_RCVD状态第三次握手客户端在接收到服务端的报文后，还要向服务器回应最后一个应答报文，将TCP首部的确认应答字段填入 server_isn+1，并将ACK标志位置为一，最后把报文发送给服务端，之后客户端处于 ESTABLISHED 状态注意，第三次握手是可以携带数据的连接完成服务端接收到客户端发来的应答报文，也进入了 ESTABLISHED 状态，至此连接就完成了，双方可以互相通信了三次握手解析图深层问题为什么不进行两次握手就建立连接呢[[在TCP中，为什么不能两次握手达成TCP连接]]TCP三次握手中消耗序号只有单独的 ACK 应答报文不会消耗序号，所以只有在TCP的第三次握手中（其中不夹杂信息）的报文不会消耗序号如果不进行 accept 最多有多少个连接建立成功半连接队列只要服务端接收到客户端发来的 SYN 报文时，就会将连接存放到 半连接队列中全连接队列在进行三次握手完后，TCP建立连接成功，服务端会将建立成功的连接存放在 全连接队列中全连接队列的大小 ，这个大小由 accept 函数中的 backlog 参数决定accpet 的作用能够将全连接队列中的连接，获取到应用程序中一个进程可以有多少个TCP连接这个连接数目是由系统决定的，通过 limit -a 找到 open files ，规定了一个进程最多有多少个文件描述符" }, { "title": "选择排序", "url": "/posts/%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F/", "categories": "计算机", "tags": "算法/排序", "date": "2023-01-23 02:34:00 +0000", "snippet": "算法逻辑选择排序就是通过外循环找到最小的元素，跟未排序中的第一个元素进行交换源码\t#include &lt;iostream&gt;\t#include &lt;vector&gt;\tusing namespace std;\tint main() {\t\tvector&lt;int&gt; vec{ 34, 66, 2, 5, 95, 4, 46, 27 };\t\tfor (int i = 0; ...", "content": "算法逻辑选择排序就是通过外循环找到最小的元素，跟未排序中的第一个元素进行交换源码\t#include &lt;iostream&gt;\t#include &lt;vector&gt;\tusing namespace std;\tint main() {\t\tvector&lt;int&gt; vec{ 34, 66, 2, 5, 95, 4, 46, 27 };\t\tfor (int i = 0; i &lt; vec.size() - 1; i++) {\t\t\tint mid = i;\t\t\tfor (int j = i + 1; j &lt; vec.size(); j++) {\t\t\t\tif (vec[j] &lt; vec[mid]) {\t\t\t\t\tmid = j;\t\t\t\t}\t\t\t}\t\t\tswap(vec[mid], vec[i]);\t\t}\t\tfor (int i : vec) {\t\t\tcout &lt;&lt; i &lt;&lt; \" \";\t\t}\t\treturn 0;\t}" }, { "title": "插入排序", "url": "/posts/%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F/", "categories": "计算机", "tags": "算法/排序", "date": "2023-01-23 02:34:00 +0000", "snippet": "#算法/排序循环如何界定通过像用扑克牌一样，外循环遍历每一种牌，内循环遍历每一张排好序的牌外循环跟内循环插入排序分为 排好序的区域 跟 未排好序的区域每一次外循环之后，排好序的区域就加一未排好序的区域减一内循环逻辑将从未排好序区域中取的一张牌，插入到排好序的区域，直到排序成功\t#include &lt;iostream&gt;\t#include &lt;vector&gt;\tusing na...", "content": "#算法/排序循环如何界定通过像用扑克牌一样，外循环遍历每一种牌，内循环遍历每一张排好序的牌外循环跟内循环插入排序分为 排好序的区域 跟 未排好序的区域每一次外循环之后，排好序的区域就加一未排好序的区域减一内循环逻辑将从未排好序区域中取的一张牌，插入到排好序的区域，直到排序成功\t#include &lt;iostream&gt;\t#include &lt;vector&gt;\tusing namespace std;\tint main() {\t\tvector&lt;int&gt; vec{ 34, 66, 2, 5, 95, 4, 46, 27 };\t\tfor (int i = 1; i &lt; vec.size(); ++i) {\t\t\tfor (int j = i; j &gt; 0 &amp;&amp; vec[j] &lt; vec[j - 1]; --j) {\t\t\t\tswap(vec[j], vec[j - 1]);\t\t\t}\t\t}\t\tfor (int i : vec) {\t\t\tcout &lt;&lt; i &lt;&lt; \" \";\t\t}\t\treturn 0;\t}" }, { "title": "排序算法总结", "url": "/posts/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/", "categories": "计算机", "tags": "算法/排序", "date": "2023-01-23 02:34:00 +0000", "snippet": " 排序算法是否稳定 取决于会不会对相等的元素进行交换 会不会改变相等元素之间的相对位置简单排序算法平均的时间复杂度都为 O(n^2)冒泡排序\t稳定插入排序\t稳定选择排序\t不稳定中等排序算法平均的时间复杂度都为 O(nlogn)快速排序\t不稳定归并排序\t稳定[[希尔排序]]\t不稳定", "content": " 排序算法是否稳定 取决于会不会对相等的元素进行交换 会不会改变相等元素之间的相对位置简单排序算法平均的时间复杂度都为 O(n^2)冒泡排序\t稳定插入排序\t稳定选择排序\t不稳定中等排序算法平均的时间复杂度都为 O(nlogn)快速排序\t不稳定归并排序\t稳定[[希尔排序]]\t不稳定" }, { "title": "快速排序", "url": "/posts/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/", "categories": "计算机", "tags": "算法/排序", "date": "2023-01-23 02:34:00 +0000", "snippet": "快排是使用递归实现的，将第一个元素设为key，以key为基准，先将key做个备份，然后将大于key的元素跟小于key的元素赋值到对应的边去\t#include &lt;iostream&gt;\t#include &lt;vector&gt;\tusing namespace std;\tvoid QuickSort(vector&lt;int&gt;&amp; vec, int l, int r)...", "content": "快排是使用递归实现的，将第一个元素设为key，以key为基准，先将key做个备份，然后将大于key的元素跟小于key的元素赋值到对应的边去\t#include &lt;iostream&gt;\t#include &lt;vector&gt;\tusing namespace std;\tvoid QuickSort(vector&lt;int&gt;&amp; vec, int l, int r) {\t\tif (l + 1 &gt;= r) return;\t\tint first = l;\t\tint last = r - 1;\t\tint key = vec[first];\t\twhile (first &lt; last) {\t\t\twhile (first &lt; last &amp;&amp; vec[last] &gt;= key) last--;\t\t\tvec[first] = vec[last];\t\t\twhile (first &lt; last &amp;&amp; vec[first] &lt;= key) first++;\t\t\tvec[last] = vec[first];\t\t}\t\tvec[first] = key;\t\tQuickSort(vec, l, first);\t\tQuickSort(vec, first + 1, last);\t}\tint main() {\t\tvector&lt;int&gt; vec{ 34, 66, 2, 5, 95, 4, 46, 27 };\t\tQuickSort(vec, 0, vec.size());\t\tfor (int i : vec) {\t\t\tcout &lt;&lt; i &lt;&lt; \" \";\t\t}\t\treturn 0;\t}" }, { "title": "归并排序", "url": "/posts/%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/", "categories": "计算机", "tags": "算法/排序", "date": "2023-01-23 02:34:00 +0000", "snippet": "算法逻辑采用分而治之的思想，将其对分成一个个元素为一组，后用 out-place 的方式，两两组合排序。分而治之思想 分：的过程只是为了分解 治：分为什么稳定归并排序稳定的原因是：在合并过程中，如果两个相等的元素位于不同的子序列中，合并后它们的相对顺序不会改变。这是因为在合并过程中，两个子序列中的元素是按照从小到大的顺序进行比较和合并的，从而保证了相等元素的相对顺序。code vo...", "content": "算法逻辑采用分而治之的思想，将其对分成一个个元素为一组，后用 out-place 的方式，两两组合排序。分而治之思想 分：的过程只是为了分解 治：分为什么稳定归并排序稳定的原因是：在合并过程中，如果两个相等的元素位于不同的子序列中，合并后它们的相对顺序不会改变。这是因为在合并过程中，两个子序列中的元素是按照从小到大的顺序进行比较和合并的，从而保证了相等元素的相对顺序。code void mergeCount(vector&lt;int&gt;&amp; nums, int left, int mid, int right) { vector&lt;int&gt; tmp(right - left + 1, 0); int index1 = left; int index2 = mid + 1; int index = 0; while (index1 &lt;= mid &amp;&amp; index2 &lt;= right) { if (nums[index1] &lt; nums[index2]) { tmp[index++] = nums[index1++]; } else { tmp[index++] = nums[index2++]; } } while (index1 &lt;= mid) { tmp[index++] = nums[index1++]; } while (index2 &lt;= right) { tmp[index++] = nums[index2++]; } for (int i = 0; i &lt; index; i++) { nums[left + i] = tmp[i]; } return; } void mergeSort(vector&lt;int&gt;&amp; nums, int left, int right) { if (left &gt;= right) return; int mid = left + (right - left) / 2; mergeSort(nums, left, mid); mergeSort(nums, mid + 1, right); mergeCount(nums, left, mid, right); }" }, { "title": "冒泡排序", "url": "/posts/%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F/", "categories": "计算机", "tags": "算法/排序", "date": "2023-01-23 02:34:00 +0000", "snippet": "如何记忆使用冒泡排序冒泡排序外循环的次数为元素个数减一，因为已经排完序了，所以最后一个元素不用循环内循环的次数是 vec.size() - i - 1 ，因为内循环的作用是将元素排序的每一次外循环过后都有一个元素排序成功减一外循环跟内循环为什么要都减一呢，因为数组交换的时候是当前元素跟下一个元素进行交换的注意：外循环跟内循环都是从0开始的\t```C++\t#include &lt;vecto...", "content": "如何记忆使用冒泡排序冒泡排序外循环的次数为元素个数减一，因为已经排完序了，所以最后一个元素不用循环内循环的次数是 vec.size() - i - 1 ，因为内循环的作用是将元素排序的每一次外循环过后都有一个元素排序成功减一外循环跟内循环为什么要都减一呢，因为数组交换的时候是当前元素跟下一个元素进行交换的注意：外循环跟内循环都是从0开始的\t```C++\t#include &lt;vector&gt;\t#include &lt;iostream&gt;\tusing namespace std;\tint main() {\t\tvector&lt;int&gt; vec{ 34, 66, 2, 5, 95, 4, 46, 27 };\t\tbool flag;\t\tfor (int i = 0; i &lt; vec.size() - 1; ++i) {\t\t\tflag = true;\t\t\tfor (int j = 0; j &lt; vec.size() - i - 1; ++j) {\t\t\t\tif (vec[j] &gt; vec[j + 1]) {\t\t\t\t\tswap(vec[j], vec[j + 1]);\t\t\t\t\tflag = false;\t\t\t\t}\t\t\t}\t\t\tif (flag) {\t\t\t\tbreak;\t\t\t}\t\t}\t\tfor (int i : vec) {\t\t\tcout &lt;&lt; i &lt;&lt; \" \" ;\t\t}\t\treturn 0;\t}\t```" }, { "title": "你好，世界！", "url": "/posts/hello-world/", "categories": "随笔", "tags": "生活", "date": "2022-03-26 02:34:00 +0000", "snippet": "感谢关注～这里可以放代码片段噢～//代码片段int main(){ hello world;}", "content": "感谢关注～这里可以放代码片段噢～//代码片段int main(){ hello world;}" } ]
