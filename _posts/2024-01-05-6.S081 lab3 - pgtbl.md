---
title: xv6 console.c 文件代码解析
date: 2024-01-05 10:34:00 +0800
categories: [计算机]
tags: [操作系统/6S081/源码解析]
pin: false
author: ZashJie

toc: true
comments: true
typora-root-url: ../../ZashJie.github.io
math: false
mermaid: true


---
#操作系统/6S081

## 打印页表

### 实验要求以及注意点
1. 将每一级对应的页表映射打印输出出来，打印出每个 pte 对应的 物理地址
2. 可以参照 `freewalk` 函数是怎么遍历三级页表找到最终的物理地址的
3. 不要打印非法的pte，也就是没有分配的pte是不需要进行打印的
4. 

### 所需的源码理解

[[xv6 源码解析 - pagetable_t]]

[[xv6 源码解析 - pte]]

##### PTE2PA
`#define PTE2PA(pte) (((pte) >> 10) << 12)` 这是一个宏，作用是将 pte 转换成 物理地址
pte 的后10位是对应的标志位，所以向后移10位将对应的标志位信息抹消掉，而向左移动12位的原因是为了跟 offset 的12位进行对齐（PTE - 44位物理地址 + 10位标志位 | PPN - 44位物理地址 + 12位offset）
##### kfree
将物理页释放掉，并返回到 空闲链表 头中
##### `walk()`
将通过传来的
### code
	```C
	void
	vmprint(pagetable_t pagetable, int depth) {
	if (depth >= 3) return;
	if (depth == 0)
		printf("page table %p\n", pagetable);
	for (int i = 0; i < 512; i++) {
		int d = depth;
		pte_t pte = pagetable[i];
		if (pte & PTE_V) {
		while (d--) {
			printf(".. ");
		}
		uint64 child = PTE2PA(pte);
		printf("..%d: pte %p pa %p\n", i, pte, child);

		vmprint((pagetable_t)child, depth + 1);
		}
	}
	}
	```

##### 为什么打印出来的页表一个在他头一个在尾，并且为什么尾的根页表不是511而是255

位于尾页表的是陷阱，并且实际上使用只用了38位，所以根页表最大在255
	```c
	page table 0x0000000087f6e000
	..0: pte 0x0000000021fda801 pa 0x0000000087f6a000
	.. ..0: pte 0x0000000021fda401 pa 0x0000000087f69000
	.. .. ..0: pte 0x0000000021fdac1f pa 0x0000000087f6b000
	.. .. ..1: pte 0x0000000021fda00f pa 0x0000000087f68000
	.. .. ..2: pte 0x0000000021fd9c1f pa 0x0000000087f67000
	..255: pte 0x0000000021fdb401 pa 0x0000000087f6d000
	.. ..511: pte 0x0000000021fdb001 pa 0x0000000087f6c000
	.. .. ..510: pte 0x0000000021fdd807 pa 0x0000000087f76000
	.. .. ..511: pte 0x0000000020001c0b pa 0x0000000080007000
	```

## 每个进程拥有自己的内核页表

### 实验要点
1. 在 `struct proc` 为每个进程添加一个物理页表
2. 生成一个新的页表给进程（在 `allocproc ` 函数中）
3. 确保每个进程的内核页表映射进程的内核栈（内核栈的设置都在 `proinit` 中，我们可以将其移动到 `allocproc` 中实现）
4. 在 `scheduler` 函数中调用
5. 在没有进程运行时，`scheduler` 函数 应该使用原本的 `kernel_pagetable`
6. 释放进程的内核页表在 `freeproc`
7. 需要另一种方式释放内核页表，同时不释放物理页
8. -

### 疑问

每个进程的内核栈还是要分配一个物理地址吧
	要给内核栈独立分配一个地址，不过映射在进程的内核页表上
物理页不释放，到时候给谁用？不释放的原因 
	不能够释放进程内核页表 虚拟内存 对应的 物理内存，因为会将内核的物理内存给释放掉

### code
	##### `kernel/vm.c`
	```c
	// kernel/vm.c
	pagetable_t
	kvm_map_kernalpagetable() {
	pagetable_t pgtbl = (pagetable_t) kalloc();
	memset(pgtbl, 0, PGSIZE);

	// uart registers
	kvmmap(pgtbl, UART0, UART0, PGSIZE, PTE_R | PTE_W);

	// virtio mmio disk interface
	kvmmap(pgtbl, VIRTIO0, VIRTIO0, PGSIZE, PTE_R | PTE_W);

	// CLINT
	kvmmap(pgtbl, CLINT, CLINT, 0x10000, PTE_R | PTE_W);

	// PLIC
	kvmmap(pgtbl, PLIC, PLIC, 0x400000, PTE_R | PTE_W);

	// map kernel text executable and read-only.
	kvmmap(pgtbl, KERNBASE, KERNBASE, (uint64)etext-KERNBASE, PTE_R | PTE_X);

	// map kernel data and the physical RAM we'll make use of.
	kvmmap(pgtbl, (uint64)etext, (uint64)etext, PHYSTOP-(uint64)etext, PTE_R | PTE_W);

	// map the trampoline for trap entry/exit to
	// the highest virtual address in the kernel.
	kvmmap(pgtbl, TRAMPOLINE, (uint64)trampoline, PGSIZE, PTE_R | PTE_X);

	return pgtbl;
	}

	void
	kvminit()
	{
	kernel_pagetable = kvm_map_kernalpagetable();
	}

	void
	kvmmap(pagetable_t pgtbl, uint64 va, uint64 pa, uint64 sz, int perm)

	uint64
	kvmpa(pagetable_t pgtbl, uint64 va)

	void
	uvmunmap(pagetable_t pagetable, uint64 va, uint64 npages, int do_free)

	void
	kvm_free_mapping(pagetable_t pgtbl) {
	for (int i = 0; i < 512; i++) {
		pte_t pte = pgtbl[i];
		if ((pte & PTE_V) && (pte & (PTE_R | PTE_W)) == 0) {
		uint64 child = PTE2PA(pte);
		kvm_free_mapping((pagetable_t)child);
		pgtbl[i] = 0;
		}
	}
	kfree((void*) pgtbl);
	}
	```
	##### `kernel/proc.c`
	```C
	void
	procinit(void)
	{
	struct proc *p;
	
	initlock(&pid_lock, "nextpid");
	for(p = proc; p < &proc[NPROC]; p++) {
		initlock(&p->lock, "proc");

		// delete 
		
		// char *pa = kalloc();
		// if(pa == 0)
		//   panic("kalloc");
		// uint64 va = KSTACK((int) (p - proc));
		// kvmmap(va, (uint64)pa, PGSIZE, PTE_R | PTE_W);
		// p->kstack = va;
		
		// delete
	}
	kvminithart();
	}

	static struct proc*
	allocproc(void) {
	// ...
	// An empty user page table.
	p->pagetable = proc_pagetable(p);
	if(p->pagetable == 0){
		freeproc(p);
		release(&p->lock);
		return 0;
	}

	// insert start
	char *pa = kalloc();
	if (pa == 0) {
		panic("kalloc");
	}
	uint64 va = KSTACK(0);
	p->kernel_pagetable = kvm_map_kernalpagetable();
	kvmmap(p->kernel_pagetable, va, (uint64)pa, PGSIZE, PTE_R|PTE_W);
	p->kstack = va;

	// insert over

	memset(&p->context, 0, sizeof(p->context));
	p->context.ra = (uint64)forkret;
	p->context.sp = p->kstack + PGSIZE;
	return p;
	}

	static void
	freeproc(struct proc *p)
	{
	if(p->trapframe)
		kfree((void*)p->trapframe);
	p->trapframe = 0;
	if(p->pagetable)
		proc_freepagetable(p->pagetable, p->sz);
	p->pagetable = 0;
	p->sz = 0;
	p->pid = 0;
	p->parent = 0;
	p->name[0] = 0;
	p->chan = 0;
	p->killed = 0;
	p->xstate = 0;
	
	// insert start
	kfree((void*)kvmpa(p->kernel_pagetable, p->kstack));
	p->kstack = 0;
	kvm_free_mapping(p->kernel_pagetable);
	p->kernel_pagetable = 0;
	// insert over
	
	p->state = UNUSED;
	}

	void
	scheduler(void)
	{
	struct proc *p;
	struct cpu *c = mycpu();
	
	c->proc = 0;
	for(;;){
		// Avoid deadlock by ensuring that devices can interrupt.
		intr_on();
		
		int found = 0;
		for(p = proc; p < &proc[NPROC]; p++) {
		acquire(&p->lock);
		if(p->state == RUNNABLE) {

			p->state = RUNNING;
			c->proc = p;
			
			// insert start
			w_satp(MAKE_SATP(p->kernel_pagetable));
			sfence_vma();
			// insert over
			
			swtch(&c->context, &p->context);
			
			// insert start
			kvminithart();
			//insert over

			c->proc = 0;

			found = 1;
		}
		release(&p->lock);
		}
	#if !defined (LAB_FS)
		if(found == 0) {
		intr_on();
		asm volatile("wfi");
		}
	#else
		;
	#endif
	}
	}
	```


### 简化 `copyin` `copyinstr`

### 实验要点
1. 要从用户页表跟进程的内核页表中添加映射，让内核直接从内核页表中读取对应的数据
2. xv6 的用户地址从0往上，而内核地址从较高的地址开始；要限制用户地址小于内核地址的最小值
3. 内核的最小地址是 `PLIC` 寄存器，值为 `0xC000000`，需要防止地址超过 `0xC000000`
4. 在内核映射用户地址操作时，别忘了在每个更改进程映射的点上都要更改内核页表
5. 不要忘了将 `userinit` 第一个进程中的内核用户页表包含在其内核页表中
6. 在内核模式中，内核不能够访问 `PTE_U` （只有用户模式才能够访问）
7. -
###### 内核页表与物理内存的映射图
![[xv6 内核页表与物理内存的映射图.png]]
###  根本理解

##### 映射函数
在这个实验中，最重要的是对于用户进程映射到内核页表中的理解；实际上，在进程的内核页表映射着用户进程的物理地址

### code
	##### `kernel/vm.c`
	```c
	pagetable_t
	kvm_map_kernalpagetable() {
	pagetable_t pgtbl = (pagetable_t) kalloc();
	memset(pgtbl, 0, PGSIZE);

	// uart registers
	kvmmap(pgtbl, UART0, UART0, PGSIZE, PTE_R | PTE_W);

	// virtio mmio disk interface
	kvmmap(pgtbl, VIRTIO0, VIRTIO0, PGSIZE, PTE_R | PTE_W);
	=-=
	// // CLINT
	// kvmmap(pgtbl, CLINT, CLINT, 0x10000, PTE_R | PTE_W);
	=-=
	// PLIC
	kvmmap(pgtbl, PLIC, PLIC, 0x400000, PTE_R | PTE_W);

	// map kernel text executable and read-only.
	kvmmap(pgtbl, KERNBASE, KERNBASE, (uint64)etext-KERNBASE, PTE_R | PTE_X);

	// map kernel data and the physical RAM we'll make use of.
	kvmmap(pgtbl, (uint64)etext, (uint64)etext, PHYSTOP-(uint64)etext, PTE_R | PTE_W);

	// map the trampoline for trap entry/exit to
	// the highest virtual address in the kernel.
	kvmmap(pgtbl, TRAMPOLINE, (uint64)trampoline, PGSIZE, PTE_R | PTE_X);

	return pgtbl;
	}

	void
	kvminit()
	{
	kernel_pagetable = kvm_map_kernalpagetable();
	=-=-
	// CLINT
	kvmmap(kernel_pagetable, CLINT, CLINT, 0x10000, PTE_R | PTE_W);
	-=-=
	}
	=-=-
	void
	kvm_free_mapping(pagetable_t pgtbl) {
	for (int i = 0; i < 512; i++) {
		pte_t pte = pgtbl[i];
		if ((pte & PTE_V) && (pte & (PTE_R | PTE_W)) == 0) {
		uint64 child = PTE2PA(pte);
		kvm_free_mapping((pagetable_t)child);
		pgtbl[i] = 0;
		}
	}
	kfree((void*) pgtbl);
	}

	int
	kvm_copy_mapping(pagetable_t src, pagetable_t dst, int start, int sz) {
	pte_t *pte;
	uint64 pa, i;
	uint flags;

	for(i = PGROUNDUP(start); i < sz; i += PGSIZE){
		if((pte = walk(src, i, 0)) == 0)
		panic("kvm_copy_mapping: pte should exist");
		if((*pte & PTE_V) == 0)
		panic("kvm_copy_mapping: page not present");
		pa = PTE2PA(*pte);
		flags = PTE_FLAGS(*pte) & ~PTE_U;
		
		if(mappages(dst, i, PGSIZE, pa, flags) != 0){
		goto err;
		}
	}
	return 0;

	err:
	uvmunmap(dst, PGROUNDUP(start), (i - PGROUNDUP(start)) / PGSIZE, 0);
	return -1;
	}

	uint64
	kvmdealloc(pagetable_t pagetable, uint64 oldsz, uint64 newsz)
	{
	if(newsz >= oldsz)
		return oldsz;

	if(PGROUNDUP(newsz) < PGROUNDUP(oldsz)){
		int npages = (PGROUNDUP(oldsz) - PGROUNDUP(newsz)) / PGSIZE;
		uvmunmap(pagetable, PGROUNDUP(newsz), npages, 0);
	}

	return newsz;
	}
	-=-=
	```

	##### `kernel/exec.c`
	```c
	int
	exec(char *path, char **argv)
	{
	char *s, *last;
	int i, off;
	uint64 argc, sz = 0, sp, ustack[MAXARG+1], stackbase;
	struct elfhdr elf;
	struct inode *ip;
	struct proghdr ph;
	pagetable_t pagetable = 0, oldpagetable;
	struct proc *p = myproc();

	begin_op();

	if((ip = namei(path)) == 0){
		end_op();
		return -1;
	}
	ilock(ip);

	// Check ELF header
	if(readi(ip, 0, (uint64)&elf, 0, sizeof(elf)) != sizeof(elf))
		goto bad;
	if(elf.magic != ELF_MAGIC)
		goto bad;

	if((pagetable = proc_pagetable(p)) == 0)
		goto bad;

	// Load program into memory.
	for(i=0, off=elf.phoff; i<elf.phnum; i++, off+=sizeof(ph)){
		if(readi(ip, 0, (uint64)&ph, off, sizeof(ph)) != sizeof(ph))
		goto bad;
		if(ph.type != ELF_PROG_LOAD)
		continue;
		if(ph.memsz < ph.filesz)
		goto bad;
		if(ph.vaddr + ph.memsz < ph.vaddr)
		goto bad;
		uint64 sz1;
		if((sz1 = uvmalloc(pagetable, sz, ph.vaddr + ph.memsz)) == 0)
		goto bad;
	=-=-
		if (sz1 >= PLIC)
		goto bad;
	-=-=
		sz = sz1;
		if(ph.vaddr % PGSIZE != 0)
		goto bad;
		if(loadseg(pagetable, ph.vaddr, ip, ph.off, ph.filesz) < 0)
		goto bad;
	}
	iunlockput(ip);
	end_op();
	ip = 0;

	p = myproc();
	uint64 oldsz = p->sz;

	// Allocate two pages at the next page boundary.
	// Use the second as the user stack.
	sz = PGROUNDUP(sz);
	uint64 sz1;
	if((sz1 = uvmalloc(pagetable, sz, sz + 2*PGSIZE)) == 0)
		goto bad;
	sz = sz1;
	uvmclear(pagetable, sz-2*PGSIZE);
	sp = sz;
	stackbase = sp - PGSIZE;

	// Push argument strings, prepare rest of stack in ustack.
	for(argc = 0; argv[argc]; argc++) {
		if(argc >= MAXARG)
		goto bad;
		sp -= strlen(argv[argc]) + 1;
		sp -= sp % 16; // riscv sp must be 16-byte aligned
		if(sp < stackbase)
		goto bad;
		if(copyout(pagetable, sp, argv[argc], strlen(argv[argc]) + 1) < 0)
		goto bad;
		ustack[argc] = sp;
	}
	ustack[argc] = 0;

	// push the array of argv[] pointers.
	sp -= (argc+1) * sizeof(uint64);
	sp -= sp % 16;
	if(sp < stackbase)
		goto bad;
	if(copyout(pagetable, sp, (char *)ustack, (argc+1)*sizeof(uint64)) < 0)
		goto bad;

	// arguments to user main(argc, argv)
	// argc is returned via the system call return
	// value, which goes in a0.
	p->trapframe->a1 = sp;

	// Save program name for debugging.
	for(last=s=path; *s; s++)
		if(*s == '/')
		last = s+1;
	safestrcpy(p->name, last, sizeof(p->name));
	=-=-
	uvmunmap(p->kernel_pagetable, 0, PGROUNDUP(oldsz) / PGSIZE, 0);
	kvm_copy_mapping(pagetable, p->kernel_pagetable, 0, sz);
	-=-=

	// Commit to the user image.
	oldpagetable = p->pagetable;
	p->pagetable = pagetable;
	p->sz = sz;
	p->trapframe->epc = elf.entry;  // initial program counter = main
	p->trapframe->sp = sp; // initial stack pointer
	proc_freepagetable(oldpagetable, oldsz);

	vmprint(p->pagetable, 0);
	return argc; // this ends up in a0, the first argument to main(argc, argv)

	bad:
	if(pagetable)
		proc_freepagetable(pagetable, sz);
	if(ip){
		iunlockput(ip);
		end_op();
	}
	return -1;
	}
	```
	##### `kernel/proc.c`
	```c
	void
	userinit(void)
	{
	struct proc *p;

	p = allocproc();
	initproc = p;
	
	// allocate one user page and copy init's instructions
	// and data into it.
	uvminit(p->pagetable, initcode, sizeof(initcode));
	p->sz = PGSIZE;
	=-=-
	kvm_copy_mapping(p->pagetable, p->kernel_pagetable, 0, p->sz);
	-=-=
	// prepare for the very first "return" from kernel to user.
	p->trapframe->epc = 0;      // user program counter
	p->trapframe->sp = PGSIZE;  // user stack pointer

	safestrcpy(p->name, "initcode", sizeof(p->name));
	p->cwd = namei("/");

	p->state = RUNNABLE;

	release(&p->lock);
	}
	int
	growproc(int n)
	{
	uint sz;
	struct proc *p = myproc();

	sz = p->sz;
	if(n > 0){
		int sz1;
		if((sz1 = uvmalloc(p->pagetable, sz, sz + n)) == 0) {
		return -1;
		}
		=-=-
		if (kvm_copy_mapping(p->pagetable, p->kernel_pagetable, sz, sz + n)) {
		return -1;
		}
		-=-=
		sz = sz1;
	} else if(n < 0){
	=-=-
		uvmdealloc(p->pagetable, sz, sz + n);
		sz = kvmdealloc(p->kernel_pagetable, sz, sz + n);
		-=-=
	}
	p->sz = sz;
	return 0;
	}

	int
	fork(void)
	{
	int i, pid;
	struct proc *np;
	struct proc *p = myproc();

	// Allocate process.
	if((np = allocproc()) == 0){
		return -1;
	}
	=-=-
	// Copy user memory from parent to child.
	if(uvmcopy(p->pagetable, np->pagetable, p->sz) < 0 ||
		kvm_copy_mapping(np->pagetable, np->kernel_pagetable, 0, p->sz) < 0){
	-=-=
		freeproc(np);
		release(&np->lock);
		return -1;
	}
	np->sz = p->sz;

	np->parent = p;

	// copy saved user registers.
	*(np->trapframe) = *(p->trapframe);

	// Cause fork to return 0 in the child.
	np->trapframe->a0 = 0;

	// increment reference counts on open file descriptors.
	for(i = 0; i < NOFILE; i++)
		if(p->ofile[i])
		np->ofile[i] = filedup(p->ofile[i]);
	np->cwd = idup(p->cwd);

	safestrcpy(np->name, p->name, sizeof(p->name));

	pid = np->pid;

	np->state = RUNNABLE;

	release(&np->lock);

	return pid;
	}
	```


